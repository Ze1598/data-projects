// Challenge 4
// Task 1: Create an update policy
// https://learn.microsoft.com/en-us/azure/data-explorer/kusto/management/updatepolicy

.create table LogisticsTelemetryManipulated  (
    deviceId:string
    ,enqueuedTime:datetime
    ,NumOfTagsCalculated:long
    ,Temp:real
) 

.create-or-alter function ManipulateLogisticsTelemetryData()
{ 
    LogisticsTelemetry
    | extend NumOfTagsCalculated = (telemetry.TotalTags*1) - (telemetry.LostTags*1)
    | extend Temp = telemetry.Temp * 1.0
    | project 
        deviceId
        ,enqueuedTime
        ,NumOfTagsCalculated
        ,Temp 
}

.alter table LogisticsTelemetryManipulated policy update 
@'[{ "IsEnabled": true, "Source": "LogisticsTelemetry", "Query": "ManipulateLogisticsTelemetryData()", "IsTransactional": false, "PropagateIngestionProperties": false}]'

LogisticsTelemetryManipulated
| take 10


// Challenge 5
// Task 1: Declaring variables
let topTenShock = LogisticsTelemetry
| top 10 by (telemetry.Shock * 1) desc 
| distinct  deviceId;
LogisticsTelemetry
| where deviceId in (topTenShock)
| extend Temp = telemetry.Temp * 1.0
| summarize avgTemp = avg(Temp) by deviceId
| project deviceId, avgTemp


// Task 2: Add more fields to your timechart
LogisticsTelemetry
| summarize count() by 
    tostring(telemetry.TransportationMode)
    ,bin(enqueuedTime, 10m)
| render timechart 


// Task 3: Some geo-mapping
LogisticsTelemetry
| where enqueuedTime > ago(90d)
| extend  Temp = telemetry.Temp * 1.0
| top 10 by Temp desc
| extend Latitude = telemetry.Location.lat * 1.0
| extend Longitude = telemetry.Location.lon * 1.0
| project 
    deviceId
    ,Longitude
    ,Latitude
    ,Temp
| render scatterchart with (
    kind = map
    ,series = deviceId
)


// Task 4: Range
range MyNumbers from 1 to 8 step 2

range LastWeek from ago(7d) to now() step 1d

// Task 5: Anomaly detection
// https://learn.microsoft.com/en-us/azure/data-explorer/anomaly-detection#time-series-anomaly-detection
let min_t = (toscalar(LogisticsTelemetryHistorical | summarize min(enqueuedTime)));
let max_t = (toscalar(LogisticsTelemetryHistorical | summarize max(enqueuedTime)));
let step_interval = 10m;
LogisticsTelemetryHistorical
| make-series avg_shock_series = avg(Shock) on (enqueuedTime) from (min_t) to (max_t) step step_interval 
| extend anomalies_flags = series_decompose_anomalies(avg_shock_series, 1) 
| render anomalychart with(anomalycolumns = anomalies_flags, title = "avg shock anomalies") 


// Task 6: Get familiar with the new table and create a piechart
taxi
| where isnull(payment_type) <> true
| extend payment_type = tostring(payment_type)
| summarize count() by payment_type
| render piechart 


// Task 7: Datetime operations
taxi
| extend weekDay = dayofweek(tpep_pickup_datetime) / 1d
| summarize count() by weekDay
| order by weekDay asc 
| render columnchart 


// Task 8: Multiple series on the same timechart
taxi
| where tpep_pickup_datetime >= datetime(2021-07-01) and tpep_pickup_datetime <= datetime(2021-07-31)
| where passenger_count <= 4
| summarize avgTip = avg(tip_amount) by passenger_count, pickupDate = format_datetime(tpep_pickup_datetime, 'dd/MM/yyyy')
| order by pickupDate asc
| render linechart with (series = passenger_count)


// Task 9: Detect anomalies in the tip amount
taxi
| make-series avg_tip = avg(tip_amount) on (tpep_pickup_datetime) from datetime(2021-07-01) to datetime(2021-08-01) step 1h 
| extend anomalies_flags = series_decompose_anomalies(avg_tip, 5) 
| render anomalychart with(anomalycolumns = anomalies_flags) 


// Task 10: External data
let payment_type_lookup_data = (externaldata (
code:string,description:string)
[@"https://raw.githubusercontent.com/Azure/azure-kusto-microhack/main/assets/ExternalData/payment_type_lookup.csv"]
with(format="csv", ignoreFirstRecord=true))
| project tolong(code), description;
payment_type_lookup_data


// Task 11: Let's join the party
let payment_type_lookup_data = (externaldata (
code:string,description:string)
[@"https://raw.githubusercontent.com/Azure/azure-kusto-microhack/main/assets/ExternalData/payment_type_lookup.csv"]
with(format="csv", ignoreFirstRecord=true))
| project tolong(code), description;
taxi
| where tpep_pickup_datetime >= datetime(2021-07-01) and tpep_pickup_datetime <= datetime(2021-07-31)
| where isnull(payment_type) <> true
| join 
    kind = leftouter 
    payment_type_lookup_data
    on $left.payment_type == $right.code
| extend pickupDate = format_datetime(tpep_pickup_datetime, 'dd/MM/yyyy')
| summarize numTrips = count() by description, pickupDate
| order by pickupDate asc
| render linechart with (series=description)


// Task 12: Forecasting
let min_t = datetime(2021-07-01);
// No data for first week of august, this will be the predictions subset
let max_t = datetime(2021-08-07); 
taxi
| where tpep_dropoff_datetime between (min_t .. max_t)
| make-series numTrips = count() on (tpep_pickup_datetime ) from (min_t) to (max_t) step 30m 
| extend preds = series_decompose_forecast(numTrips, 24 * 7) 
| render timechart 



// Challenge 6: Visualisation
// Task 1: Prepare interactive dashboards with ADX Dashboard
let ['_transportation']=dynamic(null);
LogisticsTelemetryHistorical
| where isempty(['_transportation']) or TransportationMode  in (_transportation)
| summarize count() by 
    tostring(TransportationMode)
    ,bin(enqueuedTime, 10m)