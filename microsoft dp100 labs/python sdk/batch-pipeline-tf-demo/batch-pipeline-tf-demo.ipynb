{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Copyright (c) Microsoft Corporation. All rights reserved.  \n",
        "Licensed under the MIT License."
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "![Impressions](https://PixelServer20190423114238.azurewebsites.net/api/impressions/NotebookVM/tutorials/machine-learning-pipelines-advanced/tutorial-pipeline-batch-scoring-classification.png)"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Use Azure Machine Learning Pipelines for batch prediction\n",
        "In this tutorial, you use Azure Machine Learning service pipelines to run a batch scoring image classification job. The example job uses the pre-trained [Inception-V3](https://arxiv.org/abs/1512.00567) CNN (convolutional neural network) Tensorflow model to classify unlabeled images. Machine learning pipelines optimize your workflow with speed, portability, and reuse so you can focus on your expertise, machine learning, rather than on infrastructure and automation. After building and publishing a pipeline, you can configure a REST endpoint to enable triggering the pipeline from any HTTP library on any platform.\n",
        "\n",
        "In this tutorial, you learn the following tasks:\n",
        "\n",
        "> * Configure workspace and download sample data\n",
        "> * Create data objects to fetch and output data\n",
        "> * Download, prepare, and register the model to your workspace\n",
        "> * Provision compute targets and create a scoring script\n",
        "> * Use ParallelRunStep to do batch scoring\n",
        "> * Build, run, and publish a pipeline\n",
        "> * Enable a REST endpoint for the pipeline\n",
        "\n",
        "If you don't have an Azure subscription, create a free account before you begin. Try the [free or paid version of Azure Machine Learning service](https://aka.ms/AMLFree) today."
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prerequisites\n",
        "\n",
        "* Complete the [setup tutorial](https://docs.microsoft.com/azure/machine-learning/service/tutorial-1st-experiment-sdk-setup) if you don't already have an Azure Machine Learning service workspace or notebook virtual machine.\n",
        "* After you complete the setup tutorial, open the **tutorials/tutorial-pipeline-batch-scoring-classification.ipynb** notebook using the same notebook server.\n",
        "\n",
        "This tutorial is also available on [GitHub](https://github.com/Azure/MachineLearningNotebooks/tree/master/tutorials) if you wish to run it in your own [local environment](how-to-configure-environment.md#local). Run `pip install azureml-sdk[notebooks] azureml-pipeline-core azureml-pipeline-steps pandas requests` to get the required packages."
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Configure workspace and create datastore"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create a workspace object from the existing workspace. A [Workspace](https://docs.microsoft.com/python/api/azureml-core/azureml.core.workspace.workspace?view=azure-ml-py) is a class that accepts your Azure subscription and resource information. It also creates a cloud resource to monitor and track your model runs. `Workspace.from_config()` reads the file **config.json** and loads the authentication details into an object named `ws`. `ws` is used throughout the rest of the code in this tutorial."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Check core SDK version number\n",
        "import azureml.core\n",
        "\n",
        "print(\"SDK version:\", azureml.core.VERSION)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SDK version: 1.27.0\n"
          ]
        }
      ],
      "execution_count": 1,
      "metadata": {
        "tags": [],
        "gather": {
          "logged": 1621004961172
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import Workspace\n",
        "\n",
        "ws = Workspace.from_config()"
      ],
      "outputs": [],
      "execution_count": 2,
      "metadata": {
        "tags": [],
        "gather": {
          "logged": 1621004965092
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create a datastore for sample images\n",
        "\n",
        "Get the ImageNet evaluation public data sample from the public blob container `sampledata` on the account `pipelinedata`. Calling `register_azure_blob_container()` makes the data available to the workspace under the name `images_datastore`. Then specify the workspace default datastore as the output datastore, which you use for scoring output in the pipeline."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core.datastore import Datastore\n",
        "\n",
        "batchscore_blob = Datastore.register_azure_blob_container(\n",
        "    ws, \n",
        "    datastore_name=\"images_datastore\", \n",
        "    container_name=\"sampledata\", \n",
        "    account_name=\"pipelinedata\", \n",
        "    overwrite=True\n",
        ")\n",
        "\n",
        "def_data_store = ws.get_default_datastore()"
      ],
      "outputs": [],
      "execution_count": 3,
      "metadata": {
        "gather": {
          "logged": 1621004996866
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create data objects\n",
        "\n",
        "When building pipelines, `Dataset` objects are used for reading data from workspace datastores, and `PipelineData` objects are used for transferring intermediate data between pipeline steps.\n",
        "\n",
        "This batch scoring example only uses one pipeline step, but in use-cases with multiple steps, the typical flow will include:\n",
        "\n",
        "1. Using `Dataset` objects as **inputs** to fetch raw data, performing some transformations, then **outputting** a `PipelineData` object.\n",
        "1. Use the previous step's `PipelineData` **output object** as an *input object*, repeated for subsequent steps.\n",
        "\n",
        "For this scenario you create `Dataset` objects corresponding to the datastore directories for both the input images and the classification labels (y-test values). You also create a `PipelineData` object for the batch scoring output data."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core.dataset import Dataset\n",
        "from azureml.pipeline.core import PipelineData\n",
        "\n",
        "input_images = Dataset.File.from_files((batchscore_blob, \"batchscoring/images/\"))\n",
        "label_ds = Dataset.File.from_files((batchscore_blob, \"batchscoring/labels/\"))\n",
        "output_dir = PipelineData(name=\"scores\", datastore=def_data_store)"
      ],
      "outputs": [],
      "execution_count": 4,
      "metadata": {
        "gather": {
          "logged": 1621005129226
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, we need to register the datasets with the workspace."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "input_images = input_images.register(workspace=ws, name=\"input_images\")\n",
        "label_ds = label_ds.register(workspace=ws, name=\"label_ds\", create_new_version=True)"
      ],
      "outputs": [],
      "execution_count": 5,
      "metadata": {
        "gather": {
          "logged": 1621005133998
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download and register the model"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Download the pre-trained Tensorflow model to use it for batch scoring in the pipeline. First create a local directory where you store the model, then download and extract it."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import tarfile\n",
        "import urllib.request\n",
        "\n",
        "if not os.path.isdir(\"models\"):\n",
        "    os.mkdir(\"models\")\n",
        "    \n",
        "response = urllib.request.urlretrieve(\"http://download.tensorflow.org/models/inception_v3_2016_08_28.tar.gz\", \"model.tar.gz\")\n",
        "tar = tarfile.open(\"model.tar.gz\", \"r:gz\")\n",
        "tar.extractall(\"models\")"
      ],
      "outputs": [],
      "execution_count": 6,
      "metadata": {
        "gather": {
          "logged": 1621005343943
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now you register the model to your workspace, which allows you to easily retrieve it in the pipeline process. In the `register()` static function, the `model_name` parameter is the key you use to locate your model throughout the SDK."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "from azureml.core.model import Model\n",
        "\n",
        "# register downloaded model \n",
        "model = Model.register(model_path=\"models/inception_v3.ckpt\",\n",
        "                       model_name=\"inception\",\n",
        "                       tags={\"pretrained\": \"inception\"},\n",
        "                       description=\"Imagenet trained tensorflow inception\",\n",
        "                       workspace=ws)\n",
        "# remove the downloaded dir after registration if you wish\n",
        "shutil.rmtree(\"models\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Registering model inception\n"
          ]
        }
      ],
      "execution_count": 7,
      "metadata": {
        "gather": {
          "logged": 1621005544964
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create and attach remote compute target\n",
        "\n",
        "Azure Machine Learning service pipelines cannot be run locally, and only run on cloud resources. Remote compute targets are reusable virtual compute environments where you run experiments and work-flows. Run the following code to create a GPU-enabled [`AmlCompute`](https://docs.microsoft.com/python/api/azureml-core/azureml.core.compute.amlcompute.amlcompute?view=azure-ml-py) target, and attach it to your workspace. See the [conceptual article](https://docs.microsoft.com/azure/machine-learning/service/concept-compute-target) for more information on compute targets."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core.compute import AmlCompute, ComputeTarget\n",
        "from azureml.exceptions import ComputeTargetException\n",
        "compute_name = \"gpu-cluster\"\n",
        "\n",
        "# checks to see if compute target already exists in workspace, else create it\n",
        "try:\n",
        "    compute_target = ComputeTarget(workspace=ws, name=compute_name)\n",
        "except ComputeTargetException:\n",
        "    config = AmlCompute.provisioning_configuration(vm_size=\"STANDARD_NC6\",\n",
        "                                                   vm_priority=\"lowpriority\", \n",
        "                                                   min_nodes=0, \n",
        "                                                   max_nodes=1)\n",
        "\n",
        "    compute_target = ComputeTarget.create(workspace=ws, name=compute_name, provisioning_configuration=config)\n",
        "    compute_target.wait_for_completion(show_output=True, min_node_count=None, timeout_in_minutes=20)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating...\n",
            "SucceededProvisioning operation finished, operation \"Succeeded\"\n",
            "Succeeded\n",
            "AmlCompute wait for completion finished\n",
            "\n",
            "Minimum number of nodes requested have been provisioned\n"
          ]
        }
      ],
      "execution_count": 8,
      "metadata": {
        "gather": {
          "logged": 1621005775901
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Write a scoring script"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "To do the scoring, you create a batch scoring script `batch_scoring.py`, and write it to the current directory. The script takes a minibatch of input images, applies the classification model, and outputs the predictions to a results file.\n",
        "\n",
        "The script `batch_scoring.py` takes the following parameters, which get passed from the `ParallelRunStep` that you create later:\n",
        "\n",
        "- `--model_name`: the name of the model being used\n",
        "- `--labels_dir` : the directory path having the `labels.txt` file \n",
        "\n",
        "The pipelines infrastructure uses the `ArgumentParser` class to pass parameters into pipeline steps. For example, in the code below the first argument `--model_name` is given the property identifier `model_name`. In the `main()` function, this property is accessed using `Model.get_model_path(args.model_name)`."
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "The pipeline in this tutorial only has one step and writes the output to a file, but for multi-step pipelines, you also use `ArgumentParser` to define a directory to write output data for input to subsequent steps. See the [notebook](https://github.com/Azure/MachineLearningNotebooks/blob/master/how-to-use-azureml/machine-learning-pipelines/nyc-taxi-data-regression-model-building/nyc-taxi-data-regression-model-building.ipynb) for an example of passing data between multiple pipeline steps using the `ArgumentParser` design pattern."
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Build and run the pipeline"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Before running the pipeline, you create an object that defines the python environment and dependencies needed by your script `batch_scoring.py`. The main dependency required is Tensorflow, but you also install `azureml-core` and `azureml-dataset-runtime[fuse]` for background processes from the SDK. Create a `RunConfiguration` object using the dependencies, and also specify Docker and Docker-GPU support."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import Environment\n",
        "from azureml.core.conda_dependencies import CondaDependencies\n",
        "from azureml.core.runconfig import DEFAULT_GPU_IMAGE\n",
        "\n",
        "cd = CondaDependencies.create(pip_packages=[\"tensorflow-gpu==1.15.2\",\n",
        "                                            \"azureml-core\", \"azureml-dataset-runtime[fuse]\"])\n",
        "\n",
        "env = Environment(name=\"parallelenv\")\n",
        "env.python.conda_dependencies=cd\n",
        "env.docker.base_image = DEFAULT_GPU_IMAGE"
      ],
      "outputs": [],
      "execution_count": 9,
      "metadata": {
        "gather": {
          "logged": 1621005826596
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create the configuration to wrap the inference script\n",
        "Create the pipeline step using the script, environment configuration, and parameters. Specify the compute target you already attached to your workspace as the target of execution of the script. We will use PythonScriptStep to create the pipeline step."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.pipeline.steps import ParallelRunConfig\n",
        "\n",
        "parallel_run_config = ParallelRunConfig(\n",
        "    environment=env,\n",
        "    entry_script=\"batch_scoring.py\",\n",
        "    source_directory=\"scripts\",\n",
        "    output_action=\"append_row\",\n",
        "    append_row_file_name=\"parallel_run_step.txt\",\n",
        "    mini_batch_size=\"20\",\n",
        "    error_threshold=1,\n",
        "    compute_target=compute_target,\n",
        "    process_count_per_node=2,\n",
        "    node_count=1\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 11,
      "metadata": {
        "gather": {
          "logged": 1621005851286
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create the pipeline step\n",
        "\n",
        "A pipeline step is an object that encapsulates everything you need for running a pipeline including:\n",
        "\n",
        "* environment and dependency settings\n",
        "* the compute resource to run the pipeline on\n",
        "* input and output data, and any custom parameters\n",
        "* reference to a script or SDK-logic to run during the step\n",
        "\n",
        "There are multiple classes that inherit from the parent class [`PipelineStep`](https://docs.microsoft.com/python/api/azureml-pipeline-steps/azureml.pipeline.steps.parallelrunstep?view=azure-ml-py) to assist with building a step using certain frameworks and stacks. In this example, you use the [`ParallelRunStep`](https://docs.microsoft.com/en-us/python/api/azureml-contrib-pipeline-steps/azureml.contrib.pipeline.steps.parallelrunstep?view=azure-ml-py) class to define your step logic using a scoring script. \n",
        "\n",
        "An object reference in the `outputs` array becomes available as an **input** for a subsequent pipeline step, for scenarios where there is more than one step."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.pipeline.steps import ParallelRunStep\n",
        "from datetime import datetime\n",
        "import uuid\n",
        "\n",
        "parallel_step_name = \"batchscoring-\" + datetime.now().strftime(\"%Y%m%d%H%M\")\n",
        "\n",
        "label_config = label_ds.as_named_input(\"labels_input\").as_mount(\"/tmp/{}\".format(str(uuid.uuid4())))\n",
        "\n",
        "batch_score_step = ParallelRunStep(\n",
        "    name=parallel_step_name,\n",
        "    inputs=[input_images.as_named_input(\"input_images\")],\n",
        "    output=output_dir,\n",
        "    arguments=[\"--model_name\", \"inception\",\n",
        "               \"--labels_dir\", label_config],\n",
        "    side_inputs=[label_config],\n",
        "    parallel_run_config=parallel_run_config,\n",
        "    allow_reuse=False\n",
        ")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "'enabled' is deprecated. Please use the azureml.core.runconfig.DockerConfiguration object with the 'use_docker' param instead.\n"
          ]
        }
      ],
      "execution_count": 12,
      "metadata": {
        "gather": {
          "logged": 1621005879039
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For a list of all classes for different step types, see the [steps package](https://docs.microsoft.com/python/api/azureml-pipeline-steps/azureml.pipeline.steps?view=azure-ml-py)."
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Run the pipeline\n",
        "\n",
        "Now you run the pipeline. First create a `Pipeline` object with your workspace reference and the pipeline step you created. The `steps` parameter is an array of steps, and in this case there is only one step for batch scoring. To build pipelines with multiple steps, you place the steps in order in this array.\n",
        "\n",
        "Next use the `Experiment.submit()` function to submit the pipeline for execution. You also specify the custom parameter `param_batch_size`. The `wait_for_completion` function will output logs during the pipeline build process, which allows you to see current progress.\n",
        "\n",
        "Note: The first pipeline run takes roughly **15 minutes**, as all dependencies must be downloaded, a Docker image is created, and the Python environment is provisioned/created. Running it again takes significantly less time as those resources are reused. However, total run time depends on the workload of your scripts and processes running in each pipeline step."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import Experiment\n",
        "from azureml.pipeline.core import Pipeline\n",
        "\n",
        "pipeline = Pipeline(workspace=ws, steps=[batch_score_step])\n",
        "pipeline_run = Experiment(ws, \"Tutorial-Batch-Scoring\").submit(pipeline)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created step batchscoring-202105141524 [99bd8dcd][6a3a73f1-6a61-4b8d-81a2-0ef73460d824], (This step will run and generate new outputs)\n",
            "Submitted PipelineRun 7c4df5b6-6473-495c-856e-61edf34f3ef6\n",
            "Link to Azure Machine Learning Portal: https://ml.azure.com/runs/7c4df5b6-6473-495c-856e-61edf34f3ef6?wsid=/subscriptions/df741348-6c47-45d1-9bfc-1b8dbf6a4efa/resourcegroups/aml-study-jc/workspaces/aml-study-jc&tid=d51de596-45a0-4aa5-a0d8-47d1c958aa32\n"
          ]
        }
      ],
      "execution_count": 13,
      "metadata": {
        "gather": {
          "logged": 1621007040592
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This will output information of the pipeline run, including the link to the details page of portal.\n",
        "pipeline_run"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 14,
          "data": {
            "text/plain": "Run(Experiment: Tutorial-Batch-Scoring,\nId: 7c4df5b6-6473-495c-856e-61edf34f3ef6,\nType: azureml.PipelineRun,\nStatus: Preparing)",
            "text/html": "<table style=\"width:100%\"><tr><th>Experiment</th><th>Id</th><th>Type</th><th>Status</th><th>Details Page</th><th>Docs Page</th></tr><tr><td>Tutorial-Batch-Scoring</td><td>7c4df5b6-6473-495c-856e-61edf34f3ef6</td><td>azureml.PipelineRun</td><td>Preparing</td><td><a href=\"https://ml.azure.com/runs/7c4df5b6-6473-495c-856e-61edf34f3ef6?wsid=/subscriptions/df741348-6c47-45d1-9bfc-1b8dbf6a4efa/resourcegroups/aml-study-jc/workspaces/aml-study-jc&amp;tid=d51de596-45a0-4aa5-a0d8-47d1c958aa32\" target=\"_blank\" rel=\"noopener\">Link to Azure Machine Learning studio</a></td><td><a href=\"https://docs.microsoft.com/en-us/python/api/overview/azure/ml/intro?view=azure-ml-py\" target=\"_blank\" rel=\"noopener\">Link to Documentation</a></td></tr></table>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 14,
      "metadata": {
        "gather": {
          "logged": 1621007040736
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Wait the run for completion and show output log to console\n",
        "pipeline_run.wait_for_completion(show_output=True)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PipelineRunId: 7c4df5b6-6473-495c-856e-61edf34f3ef6\n",
            "Link to Azure Machine Learning Portal: https://ml.azure.com/runs/7c4df5b6-6473-495c-856e-61edf34f3ef6?wsid=/subscriptions/df741348-6c47-45d1-9bfc-1b8dbf6a4efa/resourcegroups/aml-study-jc/workspaces/aml-study-jc&tid=d51de596-45a0-4aa5-a0d8-47d1c958aa32\n",
            "PipelineRun Status: NotStarted\n",
            "PipelineRun Status: Running\n",
            "\n",
            "\n",
            "StepRunId: 6a14d746-0ad3-425b-a082-5efe6bb804de\n",
            "Link to Azure Machine Learning Portal: https://ml.azure.com/runs/6a14d746-0ad3-425b-a082-5efe6bb804de?wsid=/subscriptions/df741348-6c47-45d1-9bfc-1b8dbf6a4efa/resourcegroups/aml-study-jc/workspaces/aml-study-jc&tid=d51de596-45a0-4aa5-a0d8-47d1c958aa32\n",
            "StepRun( batchscoring-202105141524 ) Status: NotStarted\n",
            "StepRun( batchscoring-202105141524 ) Status: Queued\n",
            "\n",
            "Streaming azureml-logs/20_image_build_log.txt\n",
            "=============================================\n",
            "2021/05/14 15:45:21 Downloading source code...\n",
            "2021/05/14 15:45:22 Finished downloading source code\n",
            "2021/05/14 15:45:23 Creating Docker network: acb_default_network, driver: 'bridge'\n",
            "2021/05/14 15:45:23 Successfully set up Docker network: acb_default_network\n",
            "2021/05/14 15:45:23 Setting up Docker configuration...\n",
            "2021/05/14 15:45:24 Successfully set up Docker configuration\n",
            "2021/05/14 15:45:24 Logging in to registry: 77a188029f3349489bf139726dd320ec.azurecr.io\n",
            "2021/05/14 15:45:25 Successfully logged into 77a188029f3349489bf139726dd320ec.azurecr.io\n",
            "2021/05/14 15:45:25 Executing step ID: acb_step_0. Timeout(sec): 5400, Working directory: '', Network: 'acb_default_network'\n",
            "2021/05/14 15:45:25 Scanning for dependencies...\n",
            "2021/05/14 15:45:26 Successfully scanned dependencies\n",
            "2021/05/14 15:45:26 Launching container with name: acb_step_0\n",
            "Sending build context to Docker daemon  66.56kB\n",
            "\n",
            "\n",
            "Step 1/18 : FROM mcr.microsoft.com/azureml/intelmpi2018.3-cuda10.0-cudnn7-ubuntu16.04:20210331.v1@sha256:91a7ea329ac1a0c199f3d27e3e239f6db9eb7a2c7ef3136834682bb418c1d131\n",
            "mcr.microsoft.com/azureml/intelmpi2018.3-cuda10.0-cudnn7-ubuntu16.04:20210331.v1@sha256:91a7ea329ac1a0c199f3d27e3e239f6db9eb7a2c7ef3136834682bb418c1d131: Pulling from azureml/intelmpi2018.3-cuda10.0-cudnn7-ubuntu16.04\n",
            "4007a89234b4: Already exists\n",
            "5dfa26c6b9c9: Already exists\n",
            "0ba7bf18aa40: Already exists\n",
            "4c6ec688ebe3: Already exists\n",
            "5120510b32ad: Pulling fs layer\n",
            "cebf1d88c38a: Pulling fs layer\n",
            "48ae7fad692b: Pulling fs layer\n",
            "c314d8c8d952: Pulling fs layer\n",
            "7bacc6ce4e54: Pulling fs layer\n",
            "273b24695487: Pulling fs layer\n",
            "b6028b51e34f: Pulling fs layer\n",
            "0046abad7fc1: Pulling fs layer\n",
            "cbd035c14673: Pulling fs layer\n",
            "2a9806d43e74: Pulling fs layer\n",
            "712bcced15eb: Pulling fs layer\n",
            "8efeeaafc749: Pulling fs layer\n",
            "b0a90038f745: Pulling fs layer\n",
            "ccdb1bbbd8ec: Pulling fs layer\n",
            "643608023886: Pulling fs layer\n",
            "d6a145a3e7c5: Pulling fs layer\n",
            "c314d8c8d952: Waiting\n",
            "7bacc6ce4e54: Waiting\n",
            "273b24695487: Waiting\n",
            "b6028b51e34f: Waiting\n",
            "0046abad7fc1: Waiting\n",
            "cbd035c14673: Waiting\n",
            "2a9806d43e74: Waiting\n",
            "712bcced15eb: Waiting\n",
            "8efeeaafc749: Waiting\n",
            "b0a90038f745: Waiting\n",
            "ccdb1bbbd8ec: Waiting\n",
            "643608023886: Waiting\n",
            "d6a145a3e7c5: Waiting\n",
            "48ae7fad692b: Verifying Checksum\n",
            "48ae7fad692b: Download complete\n",
            "cebf1d88c38a: Verifying Checksum\n",
            "cebf1d88c38a: Download complete\n",
            "5120510b32ad: Verifying Checksum\n",
            "5120510b32ad: Download complete\n",
            "7bacc6ce4e54: Download complete\n",
            "5120510b32ad: Pull complete\n",
            "cebf1d88c38a: Pull complete\n",
            "48ae7fad692b: Pull complete\n",
            "b6028b51e34f: Verifying Checksum\n",
            "b6028b51e34f: Download complete\n",
            "StepRun( batchscoring-202105141524 ) Status: Running\n",
            "c314d8c8d952: Verifying Checksum\n",
            "c314d8c8d952: Download complete\n",
            "c314d8c8d952: Pull complete\n",
            "7bacc6ce4e54: Pull complete\n",
            "0046abad7fc1: Verifying Checksum\n",
            "0046abad7fc1: Download complete\n",
            "2a9806d43e74: Verifying Checksum\n",
            "2a9806d43e74: Download complete\n",
            "712bcced15eb: Verifying Checksum\n",
            "712bcced15eb: Download complete\n",
            "273b24695487: Verifying Checksum\n",
            "273b24695487: Download complete\n",
            "8efeeaafc749: Verifying Checksum\n",
            "8efeeaafc749: Download complete\n",
            "ccdb1bbbd8ec: Verifying Checksum\n",
            "ccdb1bbbd8ec: Download complete\n",
            "643608023886: Verifying Checksum\n",
            "643608023886: Download complete\n",
            "d6a145a3e7c5: Verifying Checksum\n",
            "d6a145a3e7c5: Download complete\n",
            "b0a90038f745: Verifying Checksum\n",
            "b0a90038f745: Download complete\n",
            "273b24695487: Pull complete\n",
            "b6028b51e34f: Pull complete\n",
            "cbd035c14673: Verifying Checksum\n",
            "cbd035c14673: Download complete\n",
            "0046abad7fc1: Pull complete\n",
            "cbd035c14673: Pull complete\n",
            "2a9806d43e74: Pull complete\n",
            "712bcced15eb: Pull complete\n",
            "8efeeaafc749: Pull complete\n",
            "b0a90038f745: Pull complete\n",
            "ccdb1bbbd8ec: Pull complete\n",
            "643608023886: Pull complete\n",
            "d6a145a3e7c5: Pull complete\n",
            "Digest: sha256:91a7ea329ac1a0c199f3d27e3e239f6db9eb7a2c7ef3136834682bb418c1d131\n",
            "Status: Downloaded newer image for mcr.microsoft.com/azureml/intelmpi2018.3-cuda10.0-cudnn7-ubuntu16.04:20210331.v1@sha256:91a7ea329ac1a0c199f3d27e3e239f6db9eb7a2c7ef3136834682bb418c1d131\n",
            " ---> ffb5b6ce0717\n",
            "Step 2/18 : USER root\n",
            " ---> Running in 22d71e7b9569\n",
            "Removing intermediate container 22d71e7b9569\n",
            " ---> bad38cad721c\n",
            "Step 3/18 : RUN mkdir -p $HOME/.cache\n",
            " ---> Running in e7092f2058fb\n",
            "Removing intermediate container e7092f2058fb\n",
            " ---> 08a6c186fc94\n",
            "Step 4/18 : WORKDIR /\n",
            " ---> Running in 77a78d09fa27\n",
            "Removing intermediate container 77a78d09fa27\n",
            " ---> 6e2f8cec5db2\n",
            "Step 5/18 : COPY azureml-environment-setup/99brokenproxy /etc/apt/apt.conf.d/\n",
            " ---> 2529b61c99b4\n",
            "Step 6/18 : RUN if dpkg --compare-versions `conda --version | grep -oE '[^ ]+$'` lt 4.4.11; then conda install conda==4.4.11; fi\n",
            " ---> Running in d6f350892415\n",
            "Removing intermediate container d6f350892415\n",
            " ---> 2539ff13f8a7\n",
            "Step 7/18 : COPY azureml-environment-setup/mutated_conda_dependencies.yml azureml-environment-setup/mutated_conda_dependencies.yml\n",
            " ---> e490f7e54655\n",
            "Step 8/18 : RUN ldconfig /usr/local/cuda/lib64/stubs && conda env create -p /azureml-envs/azureml_5ece489a73b93cd23b52e7b86f662d47 -f azureml-environment-setup/mutated_conda_dependencies.yml && rm -rf \"$HOME/.cache/pip\" && conda clean -aqy && CONDA_ROOT_DIR=$(conda info --root) && rm -rf \"$CONDA_ROOT_DIR/pkgs\" && find \"$CONDA_ROOT_DIR\" -type d -name __pycache__ -exec rm -rf {} + && ldconfig\n",
            " ---> Running in e398907e1224\n",
            "Warning: you have pip-installed dependencies in your environment file, but you do not list pip itself as one of your conda dependencies.  Conda may not use the correct pip to install your packages, and they may end up in the wrong place.  Please add an explicit pip dependency.  I'm adding one for you, but still nagging you.\n",
            "Collecting package metadata (repodata.json): ...working... \n",
            "done\n",
            "Solving environment: ...working... done\n",
            "\n",
            "Downloading and Extracting Packages\n",
            "\n",
            "ca-certificates-2020 | 128 KB    |            |   0% \n",
            "ca-certificates-2020 | 128 KB    | ########## | 100% \n",
            "ca-certificates-2020 | 128 KB    | ########## | 100% \n",
            "\n",
            "openssl-1.0.2u       | 3.1 MB    |            |   0% \n",
            "openssl-1.0.2u       | 3.1 MB    | #######8   |  79% \n",
            "openssl-1.0.2u       | 3.1 MB    | ########## | 100% \n",
            "\n",
            "xz-5.2.5             | 438 KB    |            |   0% \n",
            "xz-5.2.5             | 438 KB    | ########## | 100% \n",
            "xz-5.2.5             | 438 KB    | ########## | 100% \n",
            "\n",
            "libedit-3.1          | 171 KB    |            |   0% \n",
            "libedit-3.1          | 171 KB    | ########## | 100% \n",
            "\n",
            "readline-7.0         | 387 KB    |            |   0% \n",
            "readline-7.0         | 387 KB    | ########## | 100% \n",
            "readline-7.0         | 387 KB    | ########## | 100% \n",
            "\n",
            "sqlite-3.23.1        | 1.5 MB    |            |   0% \n",
            "sqlite-3.23.1        | 1.5 MB    | ########## | 100% \n",
            "sqlite-3.23.1        | 1.5 MB    | ########## | 100% \n",
            "\n",
            "libgcc-ng-9.1.0      | 8.1 MB    |            |   0% \n",
            "libgcc-ng-9.1.0      | 8.1 MB    | ######1    |  61% \n",
            "libgcc-ng-9.1.0      | 8.1 MB    | ########## | 100% \n",
            "libgcc-ng-9.1.0      | 8.1 MB    | ########## | 100% \n",
            "\n",
            "python-3.6.2         | 27.0 MB   |            |   0% \n",
            "python-3.6.2         | 27.0 MB   | ##7        |  27% \n",
            "python-3.6.2         | 27.0 MB   | ######8    |  69% \n",
            "python-3.6.2         | 27.0 MB   | ########## | 100% \n",
            "python-3.6.2         | 27.0 MB   | ########## | 100% \n",
            "\n",
            "certifi-2020.6.20    | 160 KB    |            |   0% \n",
            "certifi-2020.6.20    | 160 KB    | ########## | 100% \n",
            "\n",
            "zlib-1.2.11          | 120 KB    |            |   0% \n",
            "zlib-1.2.11          | 120 KB    | ########## | 100% \n",
            "\n",
            "tk-8.6.10            | 3.2 MB    |            |   0% \n",
            "tk-8.6.10            | 3.2 MB    | ########## | 100% \n",
            "tk-8.6.10            | 3.2 MB    | ########## | 100% \n",
            "\n",
            "libstdcxx-ng-9.1.0   | 4.0 MB    |            |   0% \n",
            "libstdcxx-ng-9.1.0   | 4.0 MB    | ######3    |  63% \n",
            "libstdcxx-ng-9.1.0   | 4.0 MB    | ########## | 100% \n",
            "libstdcxx-ng-9.1.0   | 4.0 MB    | ########## | 100% \n",
            "\n",
            "wheel-0.35.1         | 36 KB     |            |   0% \n",
            "wheel-0.35.1         | 36 KB     | ########## | 100% \n",
            "\n",
            "libffi-3.2.1         | 52 KB     |            |   0% \n",
            "libffi-3.2.1         | 52 KB     | ########## | 100% \n",
            "\n",
            "setuptools-50.3.0    | 891 KB    |            |   0% \n",
            "setuptools-50.3.0    | 891 KB    | ########## | 100% \n",
            "setuptools-50.3.0    | 891 KB    | ########## | 100% \n",
            "\n",
            "pip-20.2.4           | 2.0 MB    |            |   0% \n",
            "pip-20.2.4           | 2.0 MB    | ########## | 100% \n",
            "pip-20.2.4           | 2.0 MB    | ########## | 100% \n",
            "\n",
            "ncurses-6.0          | 907 KB    |            |   0% \n",
            "ncurses-6.0          | 907 KB    | ########## | 100% \n",
            "ncurses-6.0          | 907 KB    | ########## | 100% \n",
            "Preparing transaction: ...working... done\n",
            "Verifying transaction: ...working... done\n",
            "Executing transaction: ...working... done\n",
            "Installing pip dependencies: ...working... \n",
            "Ran pip subprocess with arguments:\n",
            "['/azureml-envs/azureml_5ece489a73b93cd23b52e7b86f662d47/bin/python', '-m', 'pip', 'install', '-U', '-r', '/azureml-environment-setup/condaenv.jx2bf3tf.requirements.txt']\n",
            "Pip subprocess output:\n",
            "Collecting tensorflow-gpu==1.15.2\n",
            "  Downloading tensorflow_gpu-1.15.2-cp36-cp36m-manylinux2010_x86_64.whl (411.0 MB)\n",
            "Collecting azureml-core~=1.27.0\n",
            "  Downloading azureml_core-1.27.0-py3-none-any.whl (2.2 MB)\n",
            "Collecting azureml-dataset-runtime[fuse]~=1.27.0\n",
            "  Downloading azureml_dataset_runtime-1.27.0-py3-none-any.whl (3.4 kB)\n",
            "Collecting astor>=0.6.0\n",
            "  Downloading astor-0.8.1-py2.py3-none-any.whl (27 kB)\n",
            "Collecting opt-einsum>=2.3.2\n",
            "  Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
            "Collecting google-pasta>=0.1.6\n",
            "  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
            "Collecting tensorboard<1.16.0,>=1.15.0\n",
            "  Downloading tensorboard-1.15.0-py3-none-any.whl (3.8 MB)\n",
            "Requirement already satisfied, skipping upgrade: wheel>=0.26; python_version >= \"3\" in /azureml-envs/azureml_5ece489a73b93cd23b52e7b86f662d47/lib/python3.6/site-packages (from tensorflow-gpu==1.15.2->-r /azureml-environment-setup/condaenv.jx2bf3tf.requirements.txt (line 1)) (0.35.1)\n",
            "Collecting numpy<2.0,>=1.16.0\n",
            "  Downloading numpy-1.19.5-cp36-cp36m-manylinux2010_x86_64.whl (14.8 MB)\n",
            "Collecting six>=1.10.0\n",
            "  Downloading six-1.16.0-py2.py3-none-any.whl (11 kB)\n",
            "Collecting protobuf>=3.6.1\n",
            "  Downloading protobuf-3.17.0-cp36-cp36m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.0 MB)\n",
            "Collecting grpcio>=1.8.6\n",
            "  Downloading grpcio-1.37.1-cp36-cp36m-manylinux2014_x86_64.whl (4.2 MB)\n",
            "Collecting keras-preprocessing>=1.0.5\n",
            "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
            "Collecting wrapt>=1.11.1\n",
            "  Downloading wrapt-1.12.1.tar.gz (27 kB)\n",
            "Collecting gast==0.2.2\n",
            "  Downloading gast-0.2.2.tar.gz (10 kB)\n",
            "Collecting absl-py>=0.7.0\n",
            "  Downloading absl_py-0.12.0-py3-none-any.whl (129 kB)\n",
            "Collecting termcolor>=1.1.0\n",
            "  Downloading termcolor-1.1.0.tar.gz (3.9 kB)\n",
            "Collecting keras-applications>=1.0.8\n",
            "  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n",
            "Collecting tensorflow-estimator==1.15.1\n",
            "  Downloading tensorflow_estimator-1.15.1-py2.py3-none-any.whl (503 kB)\n",
            "Collecting pytz\n",
            "  Downloading pytz-2021.1-py2.py3-none-any.whl (510 kB)\n",
            "Collecting backports.tempfile\n",
            "  Downloading backports.tempfile-1.0-py2.py3-none-any.whl (4.4 kB)\n",
            "Collecting PyJWT<3.0.0\n",
            "  Downloading PyJWT-2.1.0-py3-none-any.whl (16 kB)\n",
            "Collecting pathspec<1.0.0\n",
            "  Downloading pathspec-0.8.1-py2.py3-none-any.whl (28 kB)\n",
            "Collecting SecretStorage<4.0.0\n",
            "  Downloading SecretStorage-3.3.1-py3-none-any.whl (15 kB)\n",
            "Collecting pyopenssl<21.0.0\n",
            "  Downloading pyOpenSSL-20.0.1-py2.py3-none-any.whl (54 kB)\n",
            "Collecting azure-mgmt-keyvault<7.0.0,>=0.40.0\n",
            "  Downloading azure_mgmt_keyvault-2.2.0-py2.py3-none-any.whl (89 kB)\n",
            "Collecting azure-graphrbac<1.0.0,>=0.40.0\n",
            "  Downloading azure_graphrbac-0.61.1-py2.py3-none-any.whl (141 kB)\n",
            "Collecting azure-common<2.0.0,>=1.1.12\n",
            "  Downloading azure_common-1.1.27-py2.py3-none-any.whl (12 kB)\n",
            "Collecting requests<3.0.0,>=2.19.1\n",
            "  Downloading requests-2.25.1-py2.py3-none-any.whl (61 kB)\n",
            "Collecting azure-mgmt-storage<16.0.0,>=1.5.0\n",
            "  Downloading azure_mgmt_storage-11.2.0-py2.py3-none-any.whl (547 kB)\n",
            "Collecting docker<5.0.0\n",
            "  Downloading docker-4.4.4-py2.py3-none-any.whl (147 kB)\n",
            "Collecting jsonpickle<3.0.0\n",
            "  Downloading jsonpickle-2.0.0-py2.py3-none-any.whl (37 kB)\n",
            "Collecting azure-mgmt-authorization<1.0.0,>=0.40.0\n",
            "  Downloading azure_mgmt_authorization-0.61.0-py2.py3-none-any.whl (94 kB)\n",
            "Collecting ndg-httpsclient\n",
            "  Downloading ndg_httpsclient-0.5.1-py3-none-any.whl (34 kB)\n",
            "Collecting azure-mgmt-resource<15.0.0,>=1.2.1\n",
            "  Downloading azure_mgmt_resource-13.0.0-py2.py3-none-any.whl (1.3 MB)\n",
            "Collecting jmespath<1.0.0\n",
            "  Downloading jmespath-0.10.0-py2.py3-none-any.whl (24 kB)\n",
            "Collecting cryptography!=1.9,!=2.0.*,!=2.1.*,!=2.2.*,<4.0.0\n",
            "  Downloading cryptography-3.4.7-cp36-abi3-manylinux2014_x86_64.whl (3.2 MB)\n",
            "Collecting urllib3>=1.23\n",
            "  Downloading urllib3-1.26.4-py2.py3-none-any.whl (153 kB)\n",
            "Collecting msrest<1.0.0,>=0.5.1\n",
            "  Downloading msrest-0.6.21-py2.py3-none-any.whl (85 kB)\n",
            "Collecting contextlib2<1.0.0\n",
            "  Downloading contextlib2-0.6.0.post1-py2.py3-none-any.whl (9.8 kB)\n",
            "Collecting python-dateutil<3.0.0,>=2.7.3\n",
            "  Downloading python_dateutil-2.8.1-py2.py3-none-any.whl (227 kB)\n",
            "Collecting adal>=1.2.0\n",
            "  Downloading adal-1.2.7-py2.py3-none-any.whl (55 kB)\n",
            "Collecting msrestazure>=0.4.33\n",
            "  Downloading msrestazure-0.6.4-py2.py3-none-any.whl (40 kB)\n",
            "Collecting azure-mgmt-containerregistry>=2.0.0\n",
            "  Downloading azure_mgmt_containerregistry-2.8.0-py2.py3-none-any.whl (718 kB)\n",
            "Collecting ruamel.yaml<1.0.0,>=0.15.35\n",
            "  Downloading ruamel.yaml-0.17.4-py3-none-any.whl (101 kB)\n",
            "Collecting azureml-dataprep<2.15.0a,>=2.14.0a\n",
            "  Downloading azureml_dataprep-2.14.2-py3-none-any.whl (39.4 MB)\n",
            "Collecting pyarrow<2.0.0,>=0.17.0\n",
            "  Downloading pyarrow-1.0.1-cp36-cp36m-manylinux2014_x86_64.whl (17.3 MB)\n",
            "Collecting fusepy<4.0.0,>=3.0.1; extra == \"fuse\"\n",
            "  Downloading fusepy-3.0.1.tar.gz (11 kB)\n",
            "Collecting werkzeug>=0.11.15\n",
            "  Downloading Werkzeug-2.0.0-py3-none-any.whl (288 kB)\n",
            "Collecting markdown>=2.6.8\n",
            "  Downloading Markdown-3.3.4-py3-none-any.whl (97 kB)\n",
            "Requirement already satisfied, skipping upgrade: setuptools>=41.0.0 in /azureml-envs/azureml_5ece489a73b93cd23b52e7b86f662d47/lib/python3.6/site-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15.2->-r /azureml-environment-setup/condaenv.jx2bf3tf.requirements.txt (line 1)) (50.3.0.post20201006)\n",
            "Collecting h5py\n",
            "  Downloading h5py-3.1.0-cp36-cp36m-manylinux1_x86_64.whl (4.0 MB)\n",
            "Collecting backports.weakref\n",
            "  Downloading backports.weakref-1.0.post1-py2.py3-none-any.whl (5.2 kB)\n",
            "Collecting jeepney>=0.6\n",
            "  Downloading jeepney-0.6.0-py3-none-any.whl (45 kB)\n",
            "Collecting idna<3,>=2.5\n",
            "  Downloading idna-2.10-py2.py3-none-any.whl (58 kB)\n",
            "Collecting chardet<5,>=3.0.2\n",
            "  Downloading chardet-4.0.0-py2.py3-none-any.whl (178 kB)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /azureml-envs/azureml_5ece489a73b93cd23b52e7b86f662d47/lib/python3.6/site-packages (from requests<3.0.0,>=2.19.1->azureml-core~=1.27.0->-r /azureml-environment-setup/condaenv.jx2bf3tf.requirements.txt (line 2)) (2020.6.20)\n",
            "Collecting websocket-client>=0.32.0\n",
            "  Downloading websocket_client-0.59.0-py2.py3-none-any.whl (67 kB)\n",
            "Collecting importlib-metadata; python_version < \"3.8\"\n",
            "  Downloading importlib_metadata-4.0.1-py3-none-any.whl (16 kB)\n",
            "Collecting pyasn1>=0.1.1\n",
            "  Downloading pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
            "Collecting cffi>=1.12\n",
            "  Downloading cffi-1.14.5-cp36-cp36m-manylinux1_x86_64.whl (401 kB)\n",
            "Collecting requests-oauthlib>=0.5.0\n",
            "  Downloading requests_oauthlib-1.3.0-py2.py3-none-any.whl (23 kB)\n",
            "Collecting isodate>=0.6.0\n",
            "  Downloading isodate-0.6.0-py2.py3-none-any.whl (45 kB)\n",
            "Collecting ruamel.yaml.clib>=0.1.2; platform_python_implementation == \"CPython\" and python_version < \"3.10\"\n",
            "  Downloading ruamel.yaml.clib-0.2.2-cp36-cp36m-manylinux1_x86_64.whl (549 kB)\n",
            "Collecting dotnetcore2<3.0.0,>=2.1.14\n",
            "  Downloading dotnetcore2-2.1.20-py3-none-manylinux1_x86_64.whl (28.7 MB)\n",
            "Collecting azure-identity<1.5.0,>=1.2.0\n",
            "  Downloading azure_identity-1.4.1-py2.py3-none-any.whl (86 kB)\n",
            "Collecting cloudpickle<2.0.0,>=1.1.0\n",
            "  Downloading cloudpickle-1.6.0-py3-none-any.whl (23 kB)\n",
            "Collecting azureml-dataprep-rslex<1.13.0a,>=1.12.0dev0\n",
            "  Downloading azureml_dataprep_rslex-1.12.1-cp36-cp36m-manylinux1_x86_64.whl (9.6 MB)\n",
            "Collecting azureml-dataprep-native<34.0.0,>=33.0.0\n",
            "  Downloading azureml_dataprep_native-33.0.0-cp36-cp36m-manylinux1_x86_64.whl (1.3 MB)\n",
            "Collecting dataclasses; python_version < \"3.7\"\n",
            "  Downloading dataclasses-0.8-py3-none-any.whl (19 kB)\n",
            "Collecting cached-property; python_version < \"3.8\"\n",
            "  Downloading cached_property-1.5.2-py2.py3-none-any.whl (7.6 kB)\n",
            "Collecting zipp>=0.5\n",
            "  Downloading zipp-3.4.1-py3-none-any.whl (5.2 kB)\n",
            "Collecting typing-extensions>=3.6.4; python_version < \"3.8\"\n",
            "  Downloading typing_extensions-3.10.0.0-py3-none-any.whl (26 kB)\n",
            "Collecting pycparser\n",
            "  Downloading pycparser-2.20-py2.py3-none-any.whl (112 kB)\n",
            "Collecting oauthlib>=3.0.0\n",
            "  Downloading oauthlib-3.1.0-py2.py3-none-any.whl (147 kB)\n",
            "Collecting distro>=1.2.0\n",
            "  Downloading distro-1.5.0-py2.py3-none-any.whl (18 kB)\n",
            "Collecting azure-core<2.0.0,>=1.0.0\n",
            "  Downloading azure_core-1.14.0-py2.py3-none-any.whl (136 kB)\n",
            "Collecting msal-extensions~=0.2.2\n",
            "  Downloading msal_extensions-0.2.2-py2.py3-none-any.whl (15 kB)\n",
            "Collecting msal<2.0.0,>=1.3.0\n",
            "  Downloading msal-1.11.0-py2.py3-none-any.whl (63 kB)\n",
            "Collecting portalocker~=1.0; platform_system != \"Windows\"\n",
            "  Downloading portalocker-1.7.1-py2.py3-none-any.whl (10 kB)\n",
            "Building wheels for collected packages: wrapt, gast, termcolor, fusepy\n",
            "  Building wheel for wrapt (setup.py): started\n",
            "  Building wheel for wrapt (setup.py): finished with status 'done'\n",
            "  Created wheel for wrapt: filename=wrapt-1.12.1-cp36-cp36m-linux_x86_64.whl size=66288 sha256=8e63870851756885a9320818271adc4c0e63ca2b6881182511e1ba0ef729b80f\n",
            "  Stored in directory: /root/.cache/pip/wheels/32/42/7f/23cae9ff6ef66798d00dc5d659088e57dbba01566f6c60db63\n",
            "  Building wheel for gast (setup.py): started\n",
            "  Building wheel for gast (setup.py): finished with status 'done'\n",
            "  Created wheel for gast: filename=gast-0.2.2-py3-none-any.whl size=7540 sha256=c2d0fe3e9b27daa45d7dd894b303104d8a9a6fd24ec535297fcaff89cea6c342\n",
            "  Stored in directory: /root/.cache/pip/wheels/19/a7/b9/0740c7a3a7d1d348f04823339274b90de25fbcd217b2ee1fbe\n",
            "  Building wheel for termcolor (setup.py): started\n",
            "  Building wheel for termcolor (setup.py): finished with status 'done'\n",
            "  Created wheel for termcolor: filename=termcolor-1.1.0-py3-none-any.whl size=4830 sha256=fd73343de2e8cdbe962cb94f5f44b4efe902589bef3b2189b51187fa128bc4e0\n",
            "  Stored in directory: /root/.cache/pip/wheels/93/2a/eb/e58dbcbc963549ee4f065ff80a59f274cc7210b6eab962acdc\n",
            "  Building wheel for fusepy (setup.py): started\n",
            "  Building wheel for fusepy (setup.py): finished with status 'done'\n",
            "  Created wheel for fusepy: filename=fusepy-3.0.1-py3-none-any.whl size=10504 sha256=2fbe6b0cc7a3c4b9d77a033ba2d8bda9d899e15b9ed9e2baf84b12e1b600979b\n",
            "  Stored in directory: /root/.cache/pip/wheels/21/5c/83/1dd7e8a232d12227e5410120f4374b33adeb4037473105b079\n",
            "Successfully built wrapt gast termcolor fusepy\n",
            "Installing collected packages: astor, numpy, opt-einsum, six, google-pasta, dataclasses, werkzeug, absl-py, zipp, typing-extensions, importlib-metadata, markdown, protobuf, grpcio, tensorboard, keras-preprocessing, wrapt, gast, termcolor, cached-property, h5py, keras-applications, tensorflow-estimator, tensorflow-gpu, pytz, backports.weakref, backports.tempfile, PyJWT, pathspec, pycparser, cffi, cryptography, jeepney, SecretStorage, pyopenssl, idna, chardet, urllib3, requests, oauthlib, requests-oauthlib, isodate, msrest, azure-common, python-dateutil, adal, msrestazure, azure-mgmt-keyvault, azure-graphrbac, azure-mgmt-storage, websocket-client, docker, jsonpickle, azure-mgmt-authorization, pyasn1, ndg-httpsclient, azure-mgmt-resource, jmespath, contextlib2, azure-mgmt-containerregistry, ruamel.yaml.clib, ruamel.yaml, azureml-core, distro, dotnetcore2, azure-core, portalocker, msal, msal-extensions, azure-identity, cloudpickle, azureml-dataprep-rslex, azureml-dataprep-native, azureml-dataprep, pyarrow, fusepy, azureml-dataset-runtime\n",
            "Successfully installed PyJWT-2.1.0 SecretStorage-3.3.1 absl-py-0.12.0 adal-1.2.7 astor-0.8.1 azure-common-1.1.27 azure-core-1.14.0 azure-graphrbac-0.61.1 azure-identity-1.4.1 azure-mgmt-authorization-0.61.0 azure-mgmt-containerregistry-2.8.0 azure-mgmt-keyvault-2.2.0 azure-mgmt-resource-13.0.0 azure-mgmt-storage-11.2.0 azureml-core-1.27.0 azureml-dataprep-2.14.2 azureml-dataprep-native-33.0.0 azureml-dataprep-rslex-1.12.1 azureml-dataset-runtime-1.27.0 backports.tempfile-1.0 backports.weakref-1.0.post1 cached-property-1.5.2 cffi-1.14.5 chardet-4.0.0 cloudpickle-1.6.0 contextlib2-0.6.0.post1 cryptography-3.4.7 dataclasses-0.8 distro-1.5.0 docker-4.4.4 dotnetcore2-2.1.20 fusepy-3.0.1 gast-0.2.2 google-pasta-0.2.0 grpcio-1.37.1 h5py-3.1.0 idna-2.10 importlib-metadata-4.0.1 isodate-0.6.0 jeepney-0.6.0 jmespath-0.10.0 jsonpickle-2.0.0 keras-applications-1.0.8 keras-preprocessing-1.1.2 markdown-3.3.4 msal-1.11.0 msal-extensions-0.2.2 msrest-0.6.21 msrestazure-0.6.4 ndg-httpsclient-0.5.1 numpy-1.19.5 oauthlib-3.1.0 opt-einsum-3.3.0 pathspec-0.8.1 portalocker-1.7.1 protobuf-3.17.0 pyarrow-1.0.1 pyasn1-0.4.8 pycparser-2.20 pyopenssl-20.0.1 python-dateutil-2.8.1 pytz-2021.1 requests-2.25.1 requests-oauthlib-1.3.0 ruamel.yaml-0.17.4 ruamel.yaml.clib-0.2.2 six-1.16.0 tensorboard-1.15.0 tensorflow-estimator-1.15.1 tensorflow-gpu-1.15.2 termcolor-1.1.0 typing-extensions-3.10.0.0 urllib3-1.26.4 websocket-client-0.59.0 werkzeug-2.0.0 wrapt-1.12.1 zipp-3.4.1\n",
            "\n",
            "done\n",
            "#\n",
            "# To activate this environment, use\n",
            "#\n",
            "#     $ conda activate /azureml-envs/azureml_5ece489a73b93cd23b52e7b86f662d47\n",
            "#\n",
            "# To deactivate an active environment, use\n",
            "#\n",
            "#     $ conda deactivate\n",
            "\n",
            "\u001b[91m\n",
            "\n",
            "==> WARNING: A newer version of conda exists. <==\n",
            "  current version: 4.9.2\n",
            "  latest version: 4.10.1\n",
            "\n",
            "Please update conda by running\n",
            "\n",
            "    $ conda update -n base -c defaults conda\n",
            "\n",
            "\n",
            "\u001b[0mWARNING: /root/.conda/pkgs does not exist\n",
            "Removing intermediate container e398907e1224\n",
            " ---> 78e8795f4b23\n",
            "Step 9/18 : ENV PATH /azureml-envs/azureml_5ece489a73b93cd23b52e7b86f662d47/bin:$PATH\n",
            " ---> Running in 95c63af13922\n",
            "Removing intermediate container 95c63af13922\n",
            " ---> 00e416ec5c6f\n",
            "Step 10/18 : COPY azureml-environment-setup/send_conda_dependencies.py azureml-environment-setup/send_conda_dependencies.py\n",
            " ---> d496431b880e\n",
            "Step 11/18 : COPY azureml-environment-setup/environment_context.json azureml-environment-setup/environment_context.json\n",
            " ---> 6a73d81ca278\n",
            "Step 12/18 : RUN python /azureml-environment-setup/send_conda_dependencies.py -p /azureml-envs/azureml_5ece489a73b93cd23b52e7b86f662d47\n",
            " ---> Running in 3557026f5398\n",
            "Report materialized dependencies for the environment\n",
            "Reading environment context\n",
            "Exporting conda environment\n",
            "Sending request with materialized conda environment details\n",
            "Successfully sent materialized environment details\n",
            "Removing intermediate container 3557026f5398\n",
            " ---> 29fab520642b\n",
            "Step 13/18 : ENV AZUREML_CONDA_ENVIRONMENT_PATH /azureml-envs/azureml_5ece489a73b93cd23b52e7b86f662d47\n",
            " ---> Running in 03504cb60638\n",
            "Removing intermediate container 03504cb60638\n",
            " ---> 72fe5890a4d7\n",
            "Step 14/18 : ENV LD_LIBRARY_PATH /azureml-envs/azureml_5ece489a73b93cd23b52e7b86f662d47/lib:$LD_LIBRARY_PATH\n",
            " ---> Running in 24a6e87d8c2c\n",
            "Removing intermediate container 24a6e87d8c2c\n",
            " ---> 90d91dc0de19\n",
            "Step 15/18 : COPY azureml-environment-setup/spark_cache.py azureml-environment-setup/log4j.properties /azureml-environment-setup/\n",
            " ---> d80780deae4a\n",
            "Step 16/18 : RUN if [ $SPARK_HOME ]; then /bin/bash -c '$SPARK_HOME/bin/spark-submit  /azureml-environment-setup/spark_cache.py'; fi\n",
            " ---> Running in 89b8528ec98c\n",
            "Removing intermediate container 89b8528ec98c\n",
            " ---> 4d360d3c944e\n",
            "Step 17/18 : ENV AZUREML_ENVIRONMENT_IMAGE True\n",
            " ---> Running in 1dc546b692af\n",
            "Removing intermediate container 1dc546b692af\n",
            " ---> 74c06c978ffa\n",
            "Step 18/18 : CMD [\"bash\"]\n",
            " ---> Running in e047e71f99c1\n",
            "\n",
            "Removing intermediate container e047e71f99c1\n",
            " ---> a7dffa66b11c\n",
            "Successfully built a7dffa66b11c\n",
            "Successfully tagged 77a188029f3349489bf139726dd320ec.azurecr.io/azureml/azureml_2bdccb7aa4b49c4830f43ee804548162:latest\n",
            "Successfully tagged 77a188029f3349489bf139726dd320ec.azurecr.io/azureml/azureml_2bdccb7aa4b49c4830f43ee804548162:1\n",
            "2021/05/14 15:54:03 Successfully executed container: acb_step_0\n",
            "2021/05/14 15:54:03 Executing step ID: acb_step_1. Timeout(sec): 5400, Working directory: '', Network: 'acb_default_network'\n",
            "2021/05/14 15:54:03 Pushing image: 77a188029f3349489bf139726dd320ec.azurecr.io/azureml/azureml_2bdccb7aa4b49c4830f43ee804548162:1, attempt 1\n",
            "The push refers to repository [77a188029f3349489bf139726dd320ec.azurecr.io/azureml/azureml_2bdccb7aa4b49c4830f43ee804548162]\n",
            "081fd2e81670: Preparing\n",
            "84e836abb417: Preparing\n",
            "48df69c26250: Preparing\n",
            "8990bc7f4f70: Preparing\n",
            "c4a442fb36df: Preparing\n",
            "fb8afe29784a: Preparing\n",
            "5bdd639900ce: Preparing\n",
            "3c15061e4095: Preparing\n",
            "8d4f9c411475: Preparing\n",
            "9c8c5b08d75f: Preparing\n",
            "ca6f84d89f23: Preparing\n",
            "df0d1517f1f0: Preparing\n",
            "f694f008f503: Preparing\n",
            "cd8bdac362ad: Preparing\n",
            "d0998c28c7ef: Preparing\n",
            "a2ff8501b4ba: Preparing\n",
            "4abe0644ee0c: Preparing\n",
            "16185635c39d: Preparing\n",
            "7dee69ba36a1: Preparing\n",
            "f00e0cd19a7e: Preparing\n",
            "25deb0d9e1c2: Preparing\n",
            "e7af3a9e91bc: Preparing\n",
            "a73d7701ab25: Preparing\n",
            "d0eb584721ac: Preparing\n",
            "b0e1bc67e3cf: Preparing\n",
            "5276d2b930fc: Preparing\n",
            "e6feec0db89a: Preparing\n",
            "697949baa658: Preparing\n",
            "935c56d8b3f9: Preparing\n",
            "fb8afe29784a: Waiting\n",
            "5bdd639900ce: Waiting\n",
            "3c15061e4095: Waiting\n",
            "8d4f9c411475: Waiting\n",
            "9c8c5b08d75f: Waiting\n",
            "ca6f84d89f23: Waiting\n",
            "df0d1517f1f0: Waiting\n",
            "f694f008f503: Waiting\n",
            "cd8bdac362ad: Waiting\n",
            "d0998c28c7ef: Waiting\n",
            "a2ff8501b4ba: Waiting\n",
            "4abe0644ee0c: Waiting\n",
            "16185635c39d: Waiting\n",
            "7dee69ba36a1: Waiting\n",
            "f00e0cd19a7e: Waiting\n",
            "25deb0d9e1c2: Waiting\n",
            "e7af3a9e91bc: Waiting\n",
            "a73d7701ab25: Waiting\n",
            "d0eb584721ac: Waiting\n",
            "b0e1bc67e3cf: Waiting\n",
            "5276d2b930fc: Waiting\n",
            "e6feec0db89a: Waiting\n",
            "697949baa658: Waiting\n",
            "935c56d8b3f9: Waiting\n",
            "48df69c26250: Pushed\n",
            "081fd2e81670: Pushed\n",
            "8990bc7f4f70: Pushed\n",
            "fb8afe29784a: Pushed\n",
            "84e836abb417: Pushed\n",
            "5bdd639900ce: Pushed\n",
            "3c15061e4095: Pushed\n",
            "8d4f9c411475: Pushed\n",
            "9c8c5b08d75f: Pushed\n",
            "ca6f84d89f23: Pushed\n",
            "df0d1517f1f0: Pushed\n",
            "d0998c28c7ef: Pushed\n",
            "a2ff8501b4ba: Pushed\n",
            "f694f008f503: Pushed\n",
            "7dee69ba36a1: Pushed\n",
            "cd8bdac362ad: Pushed\n",
            "25deb0d9e1c2: Pushed\n",
            "16185635c39d: Pushed\n",
            "a73d7701ab25: Pushed\n",
            "d0eb584721ac: Pushed\n",
            "b0e1bc67e3cf: Pushed\n",
            "5276d2b930fc: Pushed\n",
            "e6feec0db89a: Pushed\n",
            "697949baa658: Pushed\n",
            "e7af3a9e91bc: Pushed\n",
            "935c56d8b3f9: Pushed\n",
            "c4a442fb36df: Pushed\n",
            "f00e0cd19a7e: Pushed\n",
            "4abe0644ee0c: Pushed\n",
            "1: digest: sha256:cb608109c7bd8bd6e3bd99a422394c949f37260928080e35ede63280ad21def0 size: 6408\n",
            "2021/05/14 16:00:59 Successfully pushed image: 77a188029f3349489bf139726dd320ec.azurecr.io/azureml/azureml_2bdccb7aa4b49c4830f43ee804548162:1\n",
            "2021/05/14 16:00:59 Executing step ID: acb_step_2. Timeout(sec): 5400, Working directory: '', Network: 'acb_default_network'\n",
            "2021/05/14 16:00:59 Pushing image: 77a188029f3349489bf139726dd320ec.azurecr.io/azureml/azureml_2bdccb7aa4b49c4830f43ee804548162:latest, attempt 1\n",
            "The push refers to repository [77a188029f3349489bf139726dd320ec.azurecr.io/azureml/azureml_2bdccb7aa4b49c4830f43ee804548162]\n",
            "081fd2e81670: Preparing\n",
            "84e836abb417: Preparing\n",
            "48df69c26250: Preparing\n",
            "8990bc7f4f70: Preparing\n",
            "c4a442fb36df: Preparing\n",
            "fb8afe29784a: Preparing\n",
            "5bdd639900ce: Preparing\n",
            "3c15061e4095: Preparing\n",
            "8d4f9c411475: Preparing\n",
            "9c8c5b08d75f: Preparing\n",
            "ca6f84d89f23: Preparing\n",
            "df0d1517f1f0: Preparing\n",
            "f694f008f503: Preparing\n",
            "cd8bdac362ad: Preparing\n",
            "d0998c28c7ef: Preparing\n",
            "a2ff8501b4ba: Preparing\n",
            "4abe0644ee0c: Preparing\n",
            "16185635c39d: Preparing\n",
            "7dee69ba36a1: Preparing\n",
            "f00e0cd19a7e: Preparing\n",
            "25deb0d9e1c2: Preparing\n",
            "e7af3a9e91bc: Preparing\n",
            "a73d7701ab25: Preparing\n",
            "d0eb584721ac: Preparing\n",
            "b0e1bc67e3cf: Preparing\n",
            "5276d2b930fc: Preparing\n",
            "e6feec0db89a: Preparing\n",
            "697949baa658: Preparing\n",
            "935c56d8b3f9: Preparing\n",
            "fb8afe29784a: Waiting\n",
            "5bdd639900ce: Waiting\n",
            "3c15061e4095: Waiting\n",
            "8d4f9c411475: Waiting\n",
            "9c8c5b08d75f: Waiting\n",
            "ca6f84d89f23: Waiting\n",
            "df0d1517f1f0: Waiting\n",
            "f694f008f503: Waiting\n",
            "cd8bdac362ad: Waiting\n",
            "d0998c28c7ef: Waiting\n",
            "a2ff8501b4ba: Waiting\n",
            "4abe0644ee0c: Waiting\n",
            "16185635c39d: Waiting\n",
            "7dee69ba36a1: Waiting\n",
            "f00e0cd19a7e: Waiting\n",
            "25deb0d9e1c2: Waiting\n",
            "e7af3a9e91bc: Waiting\n",
            "a73d7701ab25: Waiting\n",
            "d0eb584721ac: Waiting\n",
            "b0e1bc67e3cf: Waiting\n",
            "5276d2b930fc: Waiting\n",
            "e6feec0db89a: Waiting\n",
            "697949baa658: Waiting\n",
            "935c56d8b3f9: Waiting\n",
            "081fd2e81670: Layer already exists\n",
            "48df69c26250: Layer already exists\n",
            "c4a442fb36df: Layer already exists\n",
            "8990bc7f4f70: Layer already exists\n",
            "84e836abb417: Layer already exists\n",
            "5bdd639900ce: Layer already exists\n",
            "fb8afe29784a: Layer already exists\n",
            "3c15061e4095: Layer already exists\n",
            "8d4f9c411475: Layer already exists\n",
            "9c8c5b08d75f: Layer already exists\n",
            "df0d1517f1f0: Layer already exists\n",
            "cd8bdac362ad: Layer already exists\n",
            "f694f008f503: Layer already exists\n",
            "d0998c28c7ef: Layer already exists\n",
            "4abe0644ee0c: Layer already exists\n",
            "ca6f84d89f23: Layer already exists\n",
            "a2ff8501b4ba: Layer already exists\n",
            "16185635c39d: Layer already exists\n",
            "7dee69ba36a1: Layer already exists\n",
            "f00e0cd19a7e: Layer already exists\n",
            "e7af3a9e91bc: Layer already exists\n",
            "25deb0d9e1c2: Layer already exists\n",
            "b0e1bc67e3cf: Layer already exists\n",
            "d0eb584721ac: Layer already exists\n",
            "a73d7701ab25: Layer already exists\n",
            "5276d2b930fc: Layer already exists\n",
            "935c56d8b3f9: Layer already exists\n",
            "e6feec0db89a: Layer already exists\n",
            "697949baa658: Layer already exists\n",
            "latest: digest: sha256:cb608109c7bd8bd6e3bd99a422394c949f37260928080e35ede63280ad21def0 size: 6408\n",
            "2021/05/14 16:01:01 Successfully pushed image: 77a188029f3349489bf139726dd320ec.azurecr.io/azureml/azureml_2bdccb7aa4b49c4830f43ee804548162:latest\n",
            "2021/05/14 16:01:01 Step ID: acb_step_0 marked as successful (elapsed time in seconds: 517.312225)\n",
            "2021/05/14 16:01:01 Populating digests for step ID: acb_step_0...\n",
            "2021/05/14 16:01:05 Successfully populated digests for step ID: acb_step_0\n",
            "2021/05/14 16:01:05 Step ID: acb_step_1 marked as successful (elapsed time in seconds: 416.624572)\n",
            "2021/05/14 16:01:05 Step ID: acb_step_2 marked as successful (elapsed time in seconds: 1.835850)\n",
            "2021/05/14 16:01:05 The following dependencies were found:\n",
            "2021/05/14 16:01:05 \n",
            "- image:\n",
            "    registry: 77a188029f3349489bf139726dd320ec.azurecr.io\n",
            "    repository: azureml/azureml_2bdccb7aa4b49c4830f43ee804548162\n",
            "    tag: latest\n",
            "    digest: sha256:cb608109c7bd8bd6e3bd99a422394c949f37260928080e35ede63280ad21def0\n",
            "  runtime-dependency:\n",
            "    registry: mcr.microsoft.com\n",
            "    repository: azureml/intelmpi2018.3-cuda10.0-cudnn7-ubuntu16.04\n",
            "    tag: 20210331.v1\n",
            "    digest: sha256:91a7ea329ac1a0c199f3d27e3e239f6db9eb7a2c7ef3136834682bb418c1d131\n",
            "  git: {}\n",
            "- image:\n",
            "    registry: 77a188029f3349489bf139726dd320ec.azurecr.io\n",
            "    repository: azureml/azureml_2bdccb7aa4b49c4830f43ee804548162\n",
            "    tag: \"1\"\n",
            "    digest: sha256:cb608109c7bd8bd6e3bd99a422394c949f37260928080e35ede63280ad21def0\n",
            "  runtime-dependency:\n",
            "    registry: mcr.microsoft.com\n",
            "    repository: azureml/intelmpi2018.3-cuda10.0-cudnn7-ubuntu16.04\n",
            "    tag: 20210331.v1\n",
            "    digest: sha256:91a7ea329ac1a0c199f3d27e3e239f6db9eb7a2c7ef3136834682bb418c1d131\n",
            "  git: {}\n",
            "\n",
            "\n",
            "Run ID: db2 was successful after 15m45s\n",
            "\n",
            "Streaming azureml-logs/55_azureml-execution-tvmps_04d5ecea9ed3fa7b3276f28b485962ae3b7eca25b24e0b0336c01b5cdb9614c5_p.txt\n",
            "========================================================================================================================\n",
            "2021-05-14T16:05:09Z Successfully mounted a/an Blobfuse File System at /mnt/batch/tasks/shared/LS_root/jobs/aml-study-jc/azureml/6a14d746-0ad3-425b-a082-5efe6bb804de/mounts/workspaceblobstore\n",
            "2021-05-14T16:05:09Z Failed to start nvidia-fabricmanager due to exit status 5 with output Failed to start nvidia-fabricmanager.service: Unit nvidia-fabricmanager.service not found.\n",
            ". Please ignore this if the GPUs don't utilize NVIDIA NVLink switches.\n",
            "2021-05-14T16:05:10Z Starting output-watcher...\n",
            "2021-05-14T16:05:10Z IsDedicatedCompute == False, starting polling for Low-Pri Preemption\n",
            "2021-05-14T16:05:11Z Executing 'Copy ACR Details file' on 10.0.0.5\n",
            "2021-05-14T16:05:11Z Copy ACR Details file succeeded on 10.0.0.5. Output: \n",
            ">>>   \n",
            ">>>   \n",
            "Login Succeeded\n",
            "Using default tag: latest\n",
            "latest: Pulling from azureml/azureml_4539de3ccb169db6707c8cade7afe14c\n",
            "4007a89234b4: Pulling fs layer\n",
            "5dfa26c6b9c9: Pulling fs layer\n",
            "0ba7bf18aa40: Pulling fs layer\n",
            "4c6ec688ebe3: Pulling fs layer\n",
            "574f361512d6: Pulling fs layer\n",
            "db4d1e2d7079: Pulling fs layer\n",
            "e544ee0f522d: Pulling fs layer\n",
            "c655136086be: Pulling fs layer\n",
            "2ec37f44090c: Pulling fs layer\n",
            "5fba3bd4a2c4: Pulling fs layer\n",
            "7e0ea9d0a1ab: Pulling fs layer\n",
            "da005f826951: Pulling fs layer\n",
            "ac4e1c91b241: Pulling fs layer\n",
            "efb648489c68: Pulling fs layer\n",
            "e5e2bb35fef1: Pulling fs layer\n",
            "41f64f9d12ca: Pulling fs layer\n",
            "404e390f8ac9: Pulling fs layer\n",
            "00d1c09f699a: Pulling fs layer\n",
            "4c6ec688ebe3: Waiting\n",
            "574f361512d6: Waiting\n",
            "da005f826951: Waiting\n",
            "db4d1e2d7079: Waiting\n",
            "e544ee0f522d: Waiting\n",
            "ac4e1c91b241: Waiting\n",
            "efb648489c68: Waiting\n",
            "c655136086be: Waiting\n",
            "e5e2bb35fef1: Waiting\n",
            "2ec37f44090c: Waiting\n",
            "5fba3bd4a2c4: Waiting\n",
            "41f64f9d12ca: Waiting\n",
            "7e0ea9d0a1ab: Waiting\n",
            "404e390f8ac9: Waiting\n",
            "00d1c09f699a: Waiting\n",
            "0ba7bf18aa40: Download complete\n",
            "5dfa26c6b9c9: Download complete\n",
            "4c6ec688ebe3: Verifying Checksum\n",
            "4c6ec688ebe3: Download complete\n",
            "4007a89234b4: Download complete\n",
            "db4d1e2d7079: Download complete\n",
            "e544ee0f522d: Download complete\n",
            "574f361512d6: Verifying Checksum\n",
            "574f361512d6: Download complete\n",
            "c655136086be: Download complete\n",
            "4007a89234b4: Pull complete\n",
            "7e0ea9d0a1ab: Verifying Checksum\n",
            "7e0ea9d0a1ab: Download complete\n",
            "5dfa26c6b9c9: Pull complete\n",
            "0ba7bf18aa40: Pull complete\n",
            "4c6ec688ebe3: Pull complete\n",
            "5fba3bd4a2c4: Verifying Checksum\n",
            "5fba3bd4a2c4: Download complete\n",
            "da005f826951: Verifying Checksum\n",
            "da005f826951: Download complete\n",
            "ac4e1c91b241: Verifying Checksum\n",
            "ac4e1c91b241: Download complete\n",
            "e5e2bb35fef1: Download complete\n",
            "2ec37f44090c: Verifying Checksum\n",
            "2ec37f44090c: Download complete\n",
            "404e390f8ac9: Download complete\n",
            "41f64f9d12ca: Verifying Checksum\n",
            "41f64f9d12ca: Download complete\n",
            "00d1c09f699a: Verifying Checksum\n",
            "efb648489c68: Verifying Checksum\n",
            "efb648489c68: Download complete\n",
            "574f361512d6: Pull complete\n",
            "db4d1e2d7079: Pull complete\n",
            "e544ee0f522d: Pull complete\n",
            "c655136086be: Pull complete\n",
            "2ec37f44090c: Pull complete\n",
            "5fba3bd4a2c4: Pull complete\n",
            "7e0ea9d0a1ab: Pull complete\n",
            "da005f826951: Pull complete\n",
            "ac4e1c91b241: Pull complete\n",
            "efb648489c68: Pull complete\n",
            "e5e2bb35fef1: Pull complete\n",
            "41f64f9d12ca: Pull complete\n",
            "404e390f8ac9: Pull complete\n",
            "00d1c09f699a: Pull complete\n",
            "Digest: sha256:a42e3315fb9cd2730a052be10a9492e8f265703745b1e8029604c5c178f93426\n",
            "Status: Downloaded newer image for viennaglobal.azurecr.io/azureml/azureml_4539de3ccb169db6707c8cade7afe14c:latest\n",
            "viennaglobal.azurecr.io/azureml/azureml_4539de3ccb169db6707c8cade7afe14c:latest\n",
            "2021-05-14T16:05:25Z Check if container 6a14d746-0ad3-425b-a082-5efe6bb804de_DataSidecar already exist exited with 0, \n",
            "\n",
            "\n",
            "Streaming azureml-logs/65_job_prep-tvmps_04d5ecea9ed3fa7b3276f28b485962ae3b7eca25b24e0b0336c01b5cdb9614c5_p.txt\n",
            "===============================================================================================================\n",
            "[2021-05-14T16:05:32.818216] Entering job preparation.\n",
            "[2021-05-14T16:05:33.495449] Starting job preparation.\n",
            "[2021-05-14T16:05:33.495481] Extracting the control code.\n",
            "[2021-05-14T16:05:33.518554] fetching and extracting the control code on master node.\n",
            "[2021-05-14T16:05:33.518580] Starting extract_project.\n",
            "[2021-05-14T16:05:33.518612] Starting to extract zip file.\n",
            "[2021-05-14T16:05:34.212307] Finished extracting zip file.\n",
            "[2021-05-14T16:05:34.369421] Using urllib.request Python 3.0 or later\n",
            "[2021-05-14T16:05:34.369484] Start fetching snapshots.\n",
            "[2021-05-14T16:05:34.369525] Start fetching snapshot.\n",
            "[2021-05-14T16:05:34.369544] Retrieving project from snapshot: 004cf68f-1810-41b4-a54e-af284ce9f1b9\n",
            "Starting the daemon thread to refresh tokens in background for process with pid = 49\n",
            "[2021-05-14T16:05:34.940836] Finished fetching snapshot.\n",
            "[2021-05-14T16:05:34.940868] Start fetching snapshot.\n",
            "[2021-05-14T16:05:34.940884] Retrieving project from snapshot: 81439fbe-0f2f-4759-8bda-366e4eb03f32\n",
            "[2021-05-14T16:05:49.197349] Finished fetching snapshot.\n",
            "[2021-05-14T16:05:49.197387] Finished fetching snapshots.\n",
            "[2021-05-14T16:05:49.197399] Finished extract_project.\n",
            "[2021-05-14T16:05:49.210460] Finished fetching and extracting the control code.\n",
            "[2021-05-14T16:05:49.218107] Start run_history_prep.\n",
            "[2021-05-14T16:05:49.270363] Job preparation is complete.\n",
            "[2021-05-14T16:05:49.270519] Entering Data Context Managers in Sidecar\n",
            "[2021-05-14T16:05:49.271268] Running Sidecar prep cmd...\n",
            "[2021-05-14T16:05:49.653065] INFO azureml.sidecar.sidecar: Received task: enter_contexts. Running on Linux at /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/aml-study-jc/azureml/6a14d746-0ad3-425b-a082-5efe6bb804de/mounts/workspaceblobstore/azureml/6a14d746-0ad3-425b-a082-5efe6bb804de\n",
            "[2021-05-14T16:05:49.653744] INFO azureml.sidecar.sidecar: Invoking \"enter_contexts\" task with Context Managers: {\"context_managers\": [\"Dataset:context_managers.Datasets\", \"DataStoreCopy:context_managers.DataStores\"]}\n",
            "Enter __enter__ of DatasetContextManager\n",
            "SDK version: azureml-core==1.26.0 azureml-dataprep==2.14.2. Session id: 512331ec-e61b-4640-a8bd-2ca71eeb0c25. Run id: 6a14d746-0ad3-425b-a082-5efe6bb804de.\n",
            "Processing 'input_images'.\n",
            "Processing dataset FileDataset\n",
            "{\n",
            "  \"source\": [\n",
            "    \"('images_datastore', 'batchscoring/images/')\"\n",
            "  ],\n",
            "  \"definition\": [\n",
            "    \"GetDatastoreFiles\"\n",
            "  ],\n",
            "  \"registration\": {\n",
            "    \"id\": \"06548407-d08a-4e73-abaa-735170f5dee1\",\n",
            "    \"name\": \"input_images\",\n",
            "    \"version\": 1,\n",
            "    \"workspace\": \"Workspace.create(name='aml-study-jc', subscription_id='df741348-6c47-45d1-9bfc-1b8dbf6a4efa', resource_group='aml-study-jc')\"\n",
            "  }\n",
            "}\n",
            "Mounting input_images to /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/aml-study-jc/azureml/6a14d746-0ad3-425b-a082-5efe6bb804de/wd/tmpw6zugcs0.\n",
            "Mounted input_images to /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/aml-study-jc/azureml/6a14d746-0ad3-425b-a082-5efe6bb804de/wd/tmpw6zugcs0 as folder.\n",
            "Processing 'labels_input'.\n",
            "Processing dataset FileDataset\n",
            "{\n",
            "  \"source\": [\n",
            "    \"('images_datastore', 'batchscoring/labels/')\"\n",
            "  ],\n",
            "  \"definition\": [\n",
            "    \"GetDatastoreFiles\"\n",
            "  ],\n",
            "  \"registration\": {\n",
            "    \"id\": \"ea227037-f68f-426f-b9c0-f95daaa49b32\",\n",
            "    \"name\": \"label_ds\",\n",
            "    \"version\": 1,\n",
            "    \"workspace\": \"Workspace.create(name='aml-study-jc', subscription_id='df741348-6c47-45d1-9bfc-1b8dbf6a4efa', resource_group='aml-study-jc')\"\n",
            "  }\n",
            "}\n",
            "Mounting labels_input to /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/aml-study-jc/azureml/6a14d746-0ad3-425b-a082-5efe6bb804de/wd/tmpqg8qemkq.\n",
            "Mounted labels_input to /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/aml-study-jc/azureml/6a14d746-0ad3-425b-a082-5efe6bb804de/wd/tmpqg8qemkq as folder.\n",
            "Exit __enter__ of DatasetContextManager\n",
            "Set Dataset input_images's target path to /mnt/batch/tasks/shared/LS_root/jobs/aml-study-jc/azureml/6a14d746-0ad3-425b-a082-5efe6bb804de/wd/tmpw6zugcs0\n",
            "Set Dataset labels_input's target path to /tmp/26dbf598-d03e-4ce2-a5dd-845c3a69127b\n",
            "Sidecar adding paths_to_bind: ['/mnt/batch/tasks/shared/LS_root/jobs/aml-study-jc/azureml/6a14d746-0ad3-425b-a082-5efe6bb804de/wd/tmpy0k2gn7r:/tmp/4e25fdc6-4575-4f57-9a11-14152d74fcdf/5ae22938-7645-461c-8bc1-abbb3d70be63']\n",
            "Acquired lockfile /tmp/6a14d746-0ad3-425b-a082-5efe6bb804de-datastore.lock to downloading input data references\n",
            "[2021-05-14T16:06:08.387486] INFO azureml.sidecar.task.enter_contexts: Entered Context Managers\n",
            "[2021-05-14T16:06:09.180719] Ran Sidecar prep cmd.\n",
            "[2021-05-14T16:06:09.180802] Running Context Managers in Sidecar complete.\n",
            "\n",
            "Streaming azureml-logs/70_driver_log.txt\n",
            "========================================\n",
            "2021/05/14 16:07:22 Starting App Insight Logger for task:  runTaskLet\n",
            "2021/05/14 16:07:22 Attempt 1 of http call to http://10.0.0.5:16384/sendlogstoartifacts/info\n",
            "2021/05/14 16:07:22 Attempt 1 of http call to http://10.0.0.5:16384/sendlogstoartifacts/status\n",
            "[2021-05-14T16:07:23.076694] Entering context manager injector.\n",
            "[context_manager_injector.py] Command line Options: Namespace(inject=['ProjectPythonPath:context_managers.ProjectPythonPath', 'Dataset:context_managers.Datasets', 'RunHistory:context_managers.RunHistory', 'TrackUserError:context_managers.TrackUserError'], invocation=['driver/amlbi_main.py', '--client_sdk_version', '1.27.0', '--scoring_module_name', 'batch_scoring.py', '--mini_batch_size', '20', '--error_threshold', '1', '--output_action', 'append_row', '--logging_level', 'INFO', '--run_invocation_timeout', '60', '--run_max_try', '3', '--create_snapshot_at_runtime', 'True', '--append_row_file_name', 'parallel_run_step.txt', '--output', '/mnt/batch/tasks/shared/LS_root/jobs/aml-study-jc/azureml/6a14d746-0ad3-425b-a082-5efe6bb804de/mounts/workspaceblobstore/azureml/6a14d746-0ad3-425b-a082-5efe6bb804de/scores', '--process_count_per_node', '2', '--model_name', 'inception', '--labels_dir', 'DatasetConsumptionConfig:labels_input', '--input_fds_0', 'input_images'])\n",
            "Script type = None\n",
            "[2021-05-14T16:07:24.821489] Entering Run History Context Manager.\n",
            "[2021-05-14T16:07:25.366513] Current directory: /mnt/batch/tasks/shared/LS_root/jobs/aml-study-jc/azureml/6a14d746-0ad3-425b-a082-5efe6bb804de/mounts/workspaceblobstore/azureml/6a14d746-0ad3-425b-a082-5efe6bb804de\n",
            "[2021-05-14T16:07:25.366718] Preparing to call script [driver/amlbi_main.py] with arguments:['--client_sdk_version', '1.27.0', '--scoring_module_name', 'batch_scoring.py', '--mini_batch_size', '20', '--error_threshold', '1', '--output_action', 'append_row', '--logging_level', 'INFO', '--run_invocation_timeout', '60', '--run_max_try', '3', '--create_snapshot_at_runtime', 'True', '--append_row_file_name', 'parallel_run_step.txt', '--output', '/mnt/batch/tasks/shared/LS_root/jobs/aml-study-jc/azureml/6a14d746-0ad3-425b-a082-5efe6bb804de/mounts/workspaceblobstore/azureml/6a14d746-0ad3-425b-a082-5efe6bb804de/scores', '--process_count_per_node', '2', '--model_name', 'inception', '--labels_dir', '$labels_input', '--input_fds_0', 'input_images']\n",
            "[2021-05-14T16:07:25.366809] After variable expansion, calling script [driver/amlbi_main.py] with arguments:['--client_sdk_version', '1.27.0', '--scoring_module_name', 'batch_scoring.py', '--mini_batch_size', '20', '--error_threshold', '1', '--output_action', 'append_row', '--logging_level', 'INFO', '--run_invocation_timeout', '60', '--run_max_try', '3', '--create_snapshot_at_runtime', 'True', '--append_row_file_name', 'parallel_run_step.txt', '--output', '/mnt/batch/tasks/shared/LS_root/jobs/aml-study-jc/azureml/6a14d746-0ad3-425b-a082-5efe6bb804de/mounts/workspaceblobstore/azureml/6a14d746-0ad3-425b-a082-5efe6bb804de/scores', '--process_count_per_node', '2', '--model_name', 'inception', '--labels_dir', '/tmp/26dbf598-d03e-4ce2-a5dd-845c3a69127b', '--input_fds_0', 'input_images']\n",
            "\n",
            "2021/05/14 16:07:27 Not exporting to RunHistory as the exporter is either stopped or there is no data.\n",
            "Stopped: false\n",
            "OriginalData: 1\n",
            "FilteredData: 0.\n",
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "\n",
            "\n",
            "[2021-05-14T16:08:51.821014] The experiment completed successfully. Finalizing run...\n",
            "Cleaning up all outstanding Run operations, waiting 900.0 seconds\n",
            "3 items cleaning up...\n",
            "Cleanup took 0.24554443359375 seconds\n",
            "[2021-05-14T16:08:52.326273] Finished context manager injector.\n",
            "2021/05/14 16:08:53 Attempt 1 of http call to http://10.0.0.5:16384/sendlogstoartifacts/status\n",
            "2021/05/14 16:08:53 Not exporting to RunHistory as the exporter is either stopped or there is no data.\n",
            "Stopped: false\n",
            "OriginalData: 2\n",
            "FilteredData: 0.\n",
            "2021/05/14 16:08:53 Process Exiting with Code:  0\n",
            "2021/05/14 16:08:53 All App Insights Logs was send successfully\n",
            "\n",
            "Streaming azureml-logs/75_job_post-tvmps_04d5ecea9ed3fa7b3276f28b485962ae3b7eca25b24e0b0336c01b5cdb9614c5_p.txt\n",
            "===============================================================================================================\n",
            "[2021-05-14T16:08:55.049702] Entering job release\n",
            "[2021-05-14T16:08:56.384760] Starting job release\n",
            "[2021-05-14T16:08:56.385211] Logging experiment finalizing status in history service.\n",
            "[2021-05-14T16:08:56.385832] job release stage : upload_datastore starting...\n",
            "[2021-05-14T16:08:56.386431] job release stage : start importing azureml.history._tracking in run_history_release.Starting the daemon thread to refresh tokens in background for process with pid = 481[2021-05-14T16:08:56.386706] job release stage : copy_batchai_cached_logs starting...\n",
            "\n",
            "\n",
            "[2021-05-14T16:08:56.387029] job release stage : execute_job_release starting...[2021-05-14T16:08:56.387070] job release stage : copy_batchai_cached_logs completed...\n",
            "\n",
            "[2021-05-14T16:08:56.464005] Entering context manager injector.\n",
            "[2021-05-14T16:08:56.484233] job release stage : send_run_telemetry starting...\n",
            "[2021-05-14T16:08:56.504144] job release stage : execute_job_release completed...\n",
            "[2021-05-14T16:08:56.520840] job release stage : upload_datastore completed...\n",
            "[2021-05-14T16:08:56.684600] get vm size and vm region successfully.\n",
            "[2021-05-14T16:08:56.723259] get compute meta data successfully.\n",
            "[2021-05-14T16:08:56.974861] post artifact meta request successfully.\n",
            "[2021-05-14T16:08:57.001133] upload compute record artifact successfully.\n",
            "[2021-05-14T16:08:57.001206] job release stage : send_run_telemetry completed...\n",
            "[2021-05-14T16:08:57.001689] Running in AzureML-Sidecar, starting to exit user context managers...\n",
            "[2021-05-14T16:08:57.001779] Running Sidecar release cmd...\n",
            "[2021-05-14T16:08:57.012611] INFO azureml.sidecar.sidecar: Received task: exit_contexts. Running on Linux at /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/aml-study-jc/azureml/6a14d746-0ad3-425b-a082-5efe6bb804de/mounts/workspaceblobstore/azureml/6a14d746-0ad3-425b-a082-5efe6bb804de\n",
            "Enter __exit__ of DatasetContextManager\n",
            "Unmounting /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/aml-study-jc/azureml/6a14d746-0ad3-425b-a082-5efe6bb804de/wd/tmpw6zugcs0.\n",
            "Finishing unmounting /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/aml-study-jc/azureml/6a14d746-0ad3-425b-a082-5efe6bb804de/wd/tmpw6zugcs0.\n",
            "Unmounting /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/aml-study-jc/azureml/6a14d746-0ad3-425b-a082-5efe6bb804de/wd/tmpqg8qemkq.\n",
            "fuse: failed to unmount /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/aml-study-jc/azureml/6a14d746-0ad3-425b-a082-5efe6bb804de/wd/tmpqg8qemkq: Invalid argument\n",
            "Finishing unmounting /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/aml-study-jc/azureml/6a14d746-0ad3-425b-a082-5efe6bb804de/wd/tmpqg8qemkq.\n",
            "Exit __exit__ of DatasetContextManager\n",
            "[2021-05-14T16:08:57.178259] Removing absolute paths from host...\n",
            "[2021-05-14T16:08:57.187409] INFO azureml.sidecar.task.exit_contexts: Exited Context Managers\n",
            "[2021-05-14T16:08:58.092241] Ran Sidecar release cmd.\n",
            "[2021-05-14T16:08:58.092327] Job release is complete\n",
            "\n",
            "StepRun(batchscoring-202105141524) Execution Summary\n",
            "=====================================================\n",
            "StepRun( batchscoring-202105141524 ) Status: Finished\n",
            "{'runId': '6a14d746-0ad3-425b-a082-5efe6bb804de', 'target': 'gpu-cluster', 'status': 'Completed', 'startTimeUtc': '2021-05-14T16:05:07.714186Z', 'endTimeUtc': '2021-05-14T16:09:06.332573Z', 'properties': {'ContentSnapshotId': '004cf68f-1810-41b4-a54e-af284ce9f1b9', 'StepType': 'PythonScriptStep', 'ComputeTargetType': 'AmlCompute', 'azureml.moduleid': '6a3a73f1-6a61-4b8d-81a2-0ef73460d824', 'azureml.runsource': 'azureml.StepRun', 'azureml.nodeid': '99bd8dcd', 'azureml.pipelinerunid': '7c4df5b6-6473-495c-856e-61edf34f3ef6', '_azureml.ComputeTargetType': 'amlcompute', 'ProcessInfoFile': 'azureml-logs/process_info.json', 'ProcessStatusFile': 'azureml-logs/process_status.json', 'azureml.parallelrunstep': 'true'}, 'inputDatasets': [{'dataset': {'id': '06548407-d08a-4e73-abaa-735170f5dee1'}, 'consumptionDetails': {'type': 'RunInput', 'inputName': 'input_images', 'mechanism': 'Mount'}}, {'dataset': {'id': 'ea227037-f68f-426f-b9c0-f95daaa49b32'}, 'consumptionDetails': {'type': 'RunInput', 'inputName': 'labels_input', 'mechanism': 'Mount', 'pathOnCompute': '/tmp/26dbf598-d03e-4ce2-a5dd-845c3a69127b'}}], 'outputDatasets': [], 'runDefinition': {'script': 'driver/amlbi_main.py', 'command': '', 'useAbsolutePath': False, 'arguments': ['--client_sdk_version', '1.27.0', '--scoring_module_name', 'batch_scoring.py', '--mini_batch_size', '20', '--error_threshold', '1', '--output_action', 'append_row', '--logging_level', 'INFO', '--run_invocation_timeout', '60', '--run_max_try', '3', '--create_snapshot_at_runtime', 'True', '--append_row_file_name', 'parallel_run_step.txt', '--output', '$AZUREML_DATAREFERENCE_scores', '--process_count_per_node', '2', '--model_name', 'inception', '--labels_dir', 'DatasetConsumptionConfig:labels_input', '--input_fds_0', 'input_images'], 'sourceDirectoryDataStore': None, 'framework': 'Python', 'communicator': 'None', 'target': 'gpu-cluster', 'dataReferences': {'scores': {'dataStoreName': 'workspaceblobstore', 'mode': 'Mount', 'pathOnDataStore': 'azureml/6a14d746-0ad3-425b-a082-5efe6bb804de/scores', 'pathOnCompute': None, 'overwrite': False}}, 'data': {'input_images': {'dataLocation': {'dataset': {'id': '06548407-d08a-4e73-abaa-735170f5dee1', 'name': None, 'version': '1'}, 'dataPath': None, 'uri': None}, 'mechanism': 'Mount', 'environmentVariableName': 'input_images', 'pathOnCompute': None, 'overwrite': False}, 'labels_input': {'dataLocation': {'dataset': {'id': 'ea227037-f68f-426f-b9c0-f95daaa49b32', 'name': None, 'version': '1'}, 'dataPath': None, 'uri': None}, 'mechanism': 'Mount', 'environmentVariableName': 'labels_input', 'pathOnCompute': '/tmp/26dbf598-d03e-4ce2-a5dd-845c3a69127b', 'overwrite': False}}, 'outputData': {}, 'jobName': None, 'maxRunDurationSeconds': None, 'nodeCount': 1, 'priority': None, 'credentialPassthrough': False, 'identity': None, 'environment': {'name': 'parallelenv', 'version': 'Autosave_2021-05-14T15:45:18Z_c7b48808', 'python': {'interpreterPath': 'python', 'userManagedDependencies': False, 'condaDependencies': {'channels': ['anaconda', 'conda-forge'], 'dependencies': ['python=3.6.2', {'pip': ['tensorflow-gpu==1.15.2', 'azureml-core~=1.27.0', 'azureml-dataset-runtime[fuse]~=1.27.0']}], 'name': 'azureml_5ece489a73b93cd23b52e7b86f662d47'}, 'baseCondaEnvironment': None}, 'environmentVariables': {'EXAMPLE_ENV_VAR': 'EXAMPLE_VALUE'}, 'docker': {'baseImage': 'mcr.microsoft.com/azureml/intelmpi2018.3-cuda10.0-cudnn7-ubuntu16.04:20210331.v1', 'platform': {'os': 'Linux', 'architecture': 'amd64'}, 'baseDockerfile': None, 'dockerContext': None, 'baseImageRegistry': {'address': None, 'username': None, 'password': None}, 'enabled': True, 'arguments': []}, 'spark': {'repositories': [], 'packages': [], 'precachePackages': True}, 'inferencingStackVersion': None}, 'history': {'outputCollection': True, 'directoriesToWatch': ['logs'], 'enableMLflowTracking': True, 'snapshotProject': True}, 'spark': {'configuration': {'spark.app.name': 'Azure ML Experiment', 'spark.yarn.maxAppAttempts': '1'}}, 'parallelTask': {'maxRetriesPerWorker': 0, 'workerCountPerNode': 1, 'terminalExitCodes': None, 'configuration': {}}, 'amlCompute': {'name': None, 'vmSize': None, 'retainCluster': False, 'clusterMaxNodeCount': 1}, 'aiSuperComputer': {'instanceType': None, 'imageVersion': None, 'location': None, 'aiSuperComputerStorageData': None, 'interactive': False, 'scalePolicy': None, 'virtualClusterArmId': None, 'tensorboardLogDirectory': None, 'sshPublicKey': None}, 'tensorflow': {'workerCount': 1, 'parameterServerCount': 1}, 'mpi': {'processCountPerNode': 1}, 'pyTorch': {'communicationBackend': 'nccl', 'processCount': None}, 'hdi': {'yarnDeployMode': 'Cluster'}, 'containerInstance': {'region': None, 'cpuCores': 2.0, 'memoryGb': 3.5}, 'exposedPorts': None, 'docker': {'useDocker': False, 'sharedVolumes': True, 'shmSize': '2g', 'arguments': []}, 'cmk8sCompute': {'configuration': {}}, 'commandReturnCodeConfig': {'returnCode': 'Zero', 'successfulReturnCodes': []}, 'environmentVariables': {}, 'applicationEndpoints': {}}, 'logFiles': {'azureml-logs/20_image_build_log.txt': 'https://amlstudyjc9335540415.blob.core.windows.net/azureml/ExperimentRun/dcid.6a14d746-0ad3-425b-a082-5efe6bb804de/azureml-logs/20_image_build_log.txt?sv=2019-02-02&sr=b&sig=2nchHWIKG8FcG6T8WkfqcDcyR7A7GWgxK%2FWIX5x3UOI%3D&st=2021-05-14T15%3A59%3A00Z&se=2021-05-15T00%3A09%3A00Z&sp=r', 'azureml-logs/55_azureml-execution-tvmps_04d5ecea9ed3fa7b3276f28b485962ae3b7eca25b24e0b0336c01b5cdb9614c5_p.txt': 'https://amlstudyjc9335540415.blob.core.windows.net/azureml/ExperimentRun/dcid.6a14d746-0ad3-425b-a082-5efe6bb804de/azureml-logs/55_azureml-execution-tvmps_04d5ecea9ed3fa7b3276f28b485962ae3b7eca25b24e0b0336c01b5cdb9614c5_p.txt?sv=2019-02-02&sr=b&sig=zVBm8pBQY%2FfsE4vdwcNcNb94rsyAXICCuytyw1IUxXQ%3D&st=2021-05-14T15%3A59%3A00Z&se=2021-05-15T00%3A09%3A00Z&sp=r', 'azureml-logs/65_job_prep-tvmps_04d5ecea9ed3fa7b3276f28b485962ae3b7eca25b24e0b0336c01b5cdb9614c5_p.txt': 'https://amlstudyjc9335540415.blob.core.windows.net/azureml/ExperimentRun/dcid.6a14d746-0ad3-425b-a082-5efe6bb804de/azureml-logs/65_job_prep-tvmps_04d5ecea9ed3fa7b3276f28b485962ae3b7eca25b24e0b0336c01b5cdb9614c5_p.txt?sv=2019-02-02&sr=b&sig=qWp5%2FkVnOnzbMhrgeQWBmJZ%2BNgg9VXruilXhoKnzCe8%3D&st=2021-05-14T15%3A59%3A00Z&se=2021-05-15T00%3A09%3A00Z&sp=r', 'azureml-logs/70_driver_log.txt': 'https://amlstudyjc9335540415.blob.core.windows.net/azureml/ExperimentRun/dcid.6a14d746-0ad3-425b-a082-5efe6bb804de/azureml-logs/70_driver_log.txt?sv=2019-02-02&sr=b&sig=K3jYNpOCnrIADdRImwc1CDwIUgn5YYzFf%2FYJJd%2BBfA4%3D&st=2021-05-14T15%3A59%3A00Z&se=2021-05-15T00%3A09%3A00Z&sp=r', 'azureml-logs/75_job_post-tvmps_04d5ecea9ed3fa7b3276f28b485962ae3b7eca25b24e0b0336c01b5cdb9614c5_p.txt': 'https://amlstudyjc9335540415.blob.core.windows.net/azureml/ExperimentRun/dcid.6a14d746-0ad3-425b-a082-5efe6bb804de/azureml-logs/75_job_post-tvmps_04d5ecea9ed3fa7b3276f28b485962ae3b7eca25b24e0b0336c01b5cdb9614c5_p.txt?sv=2019-02-02&sr=b&sig=FEyFAFH0n%2Bselw1etREjDkF0hG%2BEBl1Pg0BydB%2FPki4%3D&st=2021-05-14T15%3A59%3A00Z&se=2021-05-15T00%3A09%3A00Z&sp=r', 'azureml-logs/process_info.json': 'https://amlstudyjc9335540415.blob.core.windows.net/azureml/ExperimentRun/dcid.6a14d746-0ad3-425b-a082-5efe6bb804de/azureml-logs/process_info.json?sv=2019-02-02&sr=b&sig=SISnXBX5S28jdLQcnKhpzr8V%2F%2BlWdGeROOcrL8Mfzhc%3D&st=2021-05-14T15%3A59%3A00Z&se=2021-05-15T00%3A09%3A00Z&sp=r', 'azureml-logs/process_status.json': 'https://amlstudyjc9335540415.blob.core.windows.net/azureml/ExperimentRun/dcid.6a14d746-0ad3-425b-a082-5efe6bb804de/azureml-logs/process_status.json?sv=2019-02-02&sr=b&sig=V64P5%2Fio4h%2BLGTpWPQDA9MasZcukgt0Os5KfK%2BTHxAY%3D&st=2021-05-14T15%3A59%3A00Z&se=2021-05-15T00%3A09%3A00Z&sp=r', 'logs/azureml/85_azureml.log': 'https://amlstudyjc9335540415.blob.core.windows.net/azureml/ExperimentRun/dcid.6a14d746-0ad3-425b-a082-5efe6bb804de/logs/azureml/85_azureml.log?sv=2019-02-02&sr=b&sig=pa0hRObMxz77SmBD5Kx5EDq4ktfNmDSVC805sWiMH2g%3D&st=2021-05-14T15%3A59%3A00Z&se=2021-05-15T00%3A09%3A00Z&sp=r', 'logs/azureml/dataprep/backgroundProcess.log': 'https://amlstudyjc9335540415.blob.core.windows.net/azureml/ExperimentRun/dcid.6a14d746-0ad3-425b-a082-5efe6bb804de/logs/azureml/dataprep/backgroundProcess.log?sv=2019-02-02&sr=b&sig=CWcaJrQwdMtpqtHeNEF9L2QBWm7yIN%2B10iAwPl5e9rs%3D&st=2021-05-14T15%3A59%3A00Z&se=2021-05-15T00%3A09%3A00Z&sp=r', 'logs/azureml/dataprep/backgroundProcess_Telemetry.log': 'https://amlstudyjc9335540415.blob.core.windows.net/azureml/ExperimentRun/dcid.6a14d746-0ad3-425b-a082-5efe6bb804de/logs/azureml/dataprep/backgroundProcess_Telemetry.log?sv=2019-02-02&sr=b&sig=Kh%2BqwTMGv8L2JvuSkZBe4nTyPn%2BU0vJdQIKd7%2FZ1YOE%3D&st=2021-05-14T15%3A59%3A00Z&se=2021-05-15T00%3A09%3A00Z&sp=r', 'logs/azureml/executionlogs.txt': 'https://amlstudyjc9335540415.blob.core.windows.net/azureml/ExperimentRun/dcid.6a14d746-0ad3-425b-a082-5efe6bb804de/logs/azureml/executionlogs.txt?sv=2019-02-02&sr=b&sig=ulWwWR6IV68L1qC4eJsRFbwkkZrzi9A%2FLMVQWU6YFuE%3D&st=2021-05-14T15%3A59%3A00Z&se=2021-05-15T00%3A09%3A00Z&sp=r', 'logs/azureml/job_prep_azureml.log': 'https://amlstudyjc9335540415.blob.core.windows.net/azureml/ExperimentRun/dcid.6a14d746-0ad3-425b-a082-5efe6bb804de/logs/azureml/job_prep_azureml.log?sv=2019-02-02&sr=b&sig=gfOK9ZDOTpeXvRwrZD4b38MQFcLZsP9H23T335sPyIY%3D&st=2021-05-14T15%3A59%3A00Z&se=2021-05-15T00%3A09%3A00Z&sp=r', 'logs/azureml/job_release_azureml.log': 'https://amlstudyjc9335540415.blob.core.windows.net/azureml/ExperimentRun/dcid.6a14d746-0ad3-425b-a082-5efe6bb804de/logs/azureml/job_release_azureml.log?sv=2019-02-02&sr=b&sig=kZxy3pAjJ7WsEMgOn41JNXDG2SRTq%2BmzO81QID8aus0%3D&st=2021-05-14T15%3A59%3A00Z&se=2021-05-15T00%3A09%3A00Z&sp=r', 'logs/azureml/sidecar/tvmps_04d5ecea9ed3fa7b3276f28b485962ae3b7eca25b24e0b0336c01b5cdb9614c5_p/all.log': 'https://amlstudyjc9335540415.blob.core.windows.net/azureml/ExperimentRun/dcid.6a14d746-0ad3-425b-a082-5efe6bb804de/logs/azureml/sidecar/tvmps_04d5ecea9ed3fa7b3276f28b485962ae3b7eca25b24e0b0336c01b5cdb9614c5_p/all.log?sv=2019-02-02&sr=b&sig=nwQ1OWev%2B58wxK2lccAfxd8NMthxxGQOyGaxa%2Fkd2Ns%3D&st=2021-05-14T15%3A59%3A00Z&se=2021-05-15T00%3A09%3A00Z&sp=r', 'logs/azureml/sidecar/tvmps_04d5ecea9ed3fa7b3276f28b485962ae3b7eca25b24e0b0336c01b5cdb9614c5_p/task.enter_contexts.log': 'https://amlstudyjc9335540415.blob.core.windows.net/azureml/ExperimentRun/dcid.6a14d746-0ad3-425b-a082-5efe6bb804de/logs/azureml/sidecar/tvmps_04d5ecea9ed3fa7b3276f28b485962ae3b7eca25b24e0b0336c01b5cdb9614c5_p/task.enter_contexts.log?sv=2019-02-02&sr=b&sig=kYPGIEXuhH2fP6cf9LMth%2F%2F26YT53RNTxM0kJ4PZKAY%3D&st=2021-05-14T15%3A59%3A00Z&se=2021-05-15T00%3A09%3A00Z&sp=r', 'logs/azureml/sidecar/tvmps_04d5ecea9ed3fa7b3276f28b485962ae3b7eca25b24e0b0336c01b5cdb9614c5_p/task.exit_contexts.log': 'https://amlstudyjc9335540415.blob.core.windows.net/azureml/ExperimentRun/dcid.6a14d746-0ad3-425b-a082-5efe6bb804de/logs/azureml/sidecar/tvmps_04d5ecea9ed3fa7b3276f28b485962ae3b7eca25b24e0b0336c01b5cdb9614c5_p/task.exit_contexts.log?sv=2019-02-02&sr=b&sig=JbMRN6vmUtB7kQq4mki2QvfRSYrHxdH5ym9LIwTICjo%3D&st=2021-05-14T15%3A59%3A00Z&se=2021-05-15T00%3A09%3A00Z&sp=r', 'logs/azureml/stderrlogs.txt': 'https://amlstudyjc9335540415.blob.core.windows.net/azureml/ExperimentRun/dcid.6a14d746-0ad3-425b-a082-5efe6bb804de/logs/azureml/stderrlogs.txt?sv=2019-02-02&sr=b&sig=c04Sk53Tm9Wm2RfPC5qfP7qd5gUKUu3Ewta0MQZwdLA%3D&st=2021-05-14T15%3A59%3A00Z&se=2021-05-15T00%3A09%3A00Z&sp=r', 'logs/azureml/stdoutlogs.txt': 'https://amlstudyjc9335540415.blob.core.windows.net/azureml/ExperimentRun/dcid.6a14d746-0ad3-425b-a082-5efe6bb804de/logs/azureml/stdoutlogs.txt?sv=2019-02-02&sr=b&sig=JuWHsaXZocVPS6AvhcoJeM8rKu2H0p0CBtbxA71iNX0%3D&st=2021-05-14T15%3A59%3A00Z&se=2021-05-15T00%3A09%3A00Z&sp=r'}, 'submittedBy': 'Jose Costa'}\n",
            "\n",
            "\n",
            "\n",
            "PipelineRun Execution Summary\n",
            "==============================\n",
            "PipelineRun Status: Finished\n",
            "{'runId': '7c4df5b6-6473-495c-856e-61edf34f3ef6', 'status': 'Completed', 'startTimeUtc': '2021-05-14T15:44:03.010026Z', 'endTimeUtc': '2021-05-14T16:09:11.986734Z', 'properties': {'azureml.runsource': 'azureml.PipelineRun', 'runSource': 'SDK', 'runType': 'SDK', 'azureml.parameters': '{}'}, 'inputDatasets': [], 'outputDatasets': [], 'logFiles': {'logs/azureml/executionlogs.txt': 'https://amlstudyjc9335540415.blob.core.windows.net/azureml/ExperimentRun/dcid.7c4df5b6-6473-495c-856e-61edf34f3ef6/logs/azureml/executionlogs.txt?sv=2019-02-02&sr=b&sig=PR7a0YGEaq85SQcVIalOsrYfqvOXPditKKrQYo01S3A%3D&st=2021-05-14T15%3A34%3A31Z&se=2021-05-14T23%3A44%3A31Z&sp=r', 'logs/azureml/stderrlogs.txt': 'https://amlstudyjc9335540415.blob.core.windows.net/azureml/ExperimentRun/dcid.7c4df5b6-6473-495c-856e-61edf34f3ef6/logs/azureml/stderrlogs.txt?sv=2019-02-02&sr=b&sig=V3DFtoCVZrhh4Xr07PciYA7%2BKPyb8mGA0h8GGbf5%2BQo%3D&st=2021-05-14T15%3A34%3A31Z&se=2021-05-14T23%3A44%3A31Z&sp=r', 'logs/azureml/stdoutlogs.txt': 'https://amlstudyjc9335540415.blob.core.windows.net/azureml/ExperimentRun/dcid.7c4df5b6-6473-495c-856e-61edf34f3ef6/logs/azureml/stdoutlogs.txt?sv=2019-02-02&sr=b&sig=VBGDVs55JCBUz4oj5uoxVclDEMZBSnpBCfxilyFfTak%3D&st=2021-05-14T15%3A34%3A31Z&se=2021-05-14T23%3A44%3A31Z&sp=r'}, 'submittedBy': 'Jose Costa'}\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "execution_count": 15,
          "data": {
            "text/plain": "'Finished'"
          },
          "metadata": {}
        }
      ],
      "execution_count": 15,
      "metadata": {
        "gather": {
          "logged": 1621008553181
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Download and review output"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run the following code to download the output file created from the `batch_scoring.py` script, then explore the scoring results."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import tempfile\n",
        "\n",
        "batch_run = pipeline_run.find_step_run(batch_score_step.name)[0]\n",
        "batch_output = batch_run.get_output_data(output_dir.name)\n",
        "\n",
        "target_dir = tempfile.mkdtemp()\n",
        "batch_output.download(local_path=target_dir)\n",
        "result_file = os.path.join(target_dir, batch_output.path_on_datastore, parallel_run_config.append_row_file_name)\n",
        "\n",
        "df = pd.read_csv(result_file, delimiter=\":\", header=None)\n",
        "df.columns = [\"Filename\", \"Prediction\"]\n",
        "print(\"Prediction has \", df.shape[0], \" rows\")\n",
        "df.head(10) "
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction has  110  rows\n"
          ]
        },
        {
          "output_type": "execute_result",
          "execution_count": 16,
          "data": {
            "text/plain": "                       Filename  \\\n0    n01982650_8985_lobster.jpg   \n1          n02084071_77_dog.jpg   \n2       n02131653_1124_bear.jpg   \n3        n02206856_5952_bee.jpg   \n4       n02219486_28983_ant.jpg   \n5  n02268443_2817_dragonfly.jpg   \n6    n02324045_35129_rabbit.jpg   \n7     n02324045_9077_rabbit.jpg   \n8   n02342885_10908_hamster.jpg   \n9    n02342885_7641_hamster.jpg   \n\n                                          Prediction  \n0   American lobster, Northern lobster, Maine lob...  \n1                                         Rottweiler  \n2   American black bear, black bear, Ursus americ...  \n3                                                bee  \n4                                ant, emmet, pismire  \n5   \"dragonfly, darning needle, devils darning ne...  \n6         wood rabbit, cottontail, cottontail rabbit  \n7                              Angora, Angora rabbit  \n8                                            hamster  \n9         wood rabbit, cottontail, cottontail rabbit  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Filename</th>\n      <th>Prediction</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>n01982650_8985_lobster.jpg</td>\n      <td>American lobster, Northern lobster, Maine lob...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>n02084071_77_dog.jpg</td>\n      <td>Rottweiler</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>n02131653_1124_bear.jpg</td>\n      <td>American black bear, black bear, Ursus americ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>n02206856_5952_bee.jpg</td>\n      <td>bee</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>n02219486_28983_ant.jpg</td>\n      <td>ant, emmet, pismire</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>n02268443_2817_dragonfly.jpg</td>\n      <td>\"dragonfly, darning needle, devils darning ne...</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>n02324045_35129_rabbit.jpg</td>\n      <td>wood rabbit, cottontail, cottontail rabbit</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>n02324045_9077_rabbit.jpg</td>\n      <td>Angora, Angora rabbit</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>n02342885_10908_hamster.jpg</td>\n      <td>hamster</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>n02342885_7641_hamster.jpg</td>\n      <td>wood rabbit, cottontail, cottontail rabbit</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 16,
      "metadata": {
        "gather": {
          "logged": 1621008588888
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Publish and run from REST endpoint"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run the following code to publish the pipeline to your workspace. In your workspace in the portal, you can see metadata for the pipeline including run history and durations. You can also run the pipeline manually from the portal.\n",
        "\n",
        "Additionally, publishing the pipeline enables a REST endpoint to rerun the pipeline from any HTTP library on any platform."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "published_pipeline = pipeline_run.publish_pipeline(\n",
        "    name=\"Inception_v3_scoring\", description=\"Batch scoring using Inception v3 model\", version=\"1.0\")\n",
        "\n",
        "published_pipeline"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 17,
          "data": {
            "text/plain": "Pipeline(Name: Inception_v3_scoring,\nId: b1152fb0-b19a-4909-9995-5720c5c9fc67,\nStatus: Active,\nEndpoint: https://uksouth.api.azureml.ms/pipelines/v1.0/subscriptions/df741348-6c47-45d1-9bfc-1b8dbf6a4efa/resourceGroups/aml-study-jc/providers/Microsoft.MachineLearningServices/workspaces/aml-study-jc/PipelineRuns/PipelineSubmit/b1152fb0-b19a-4909-9995-5720c5c9fc67)",
            "text/html": "<table style=\"width:100%\"><tr><th>Name</th><th>Id</th><th>Status</th><th>Endpoint</th></tr><tr><td>Inception_v3_scoring</td><td><a href=\"https://ml.azure.com/pipelines/b1152fb0-b19a-4909-9995-5720c5c9fc67?wsid=/subscriptions/df741348-6c47-45d1-9bfc-1b8dbf6a4efa/resourcegroups/aml-study-jc/workspaces/aml-study-jc\" target=\"_blank\" rel=\"noopener\">b1152fb0-b19a-4909-9995-5720c5c9fc67</a></td><td>Active</td><td><a href=\"https://uksouth.api.azureml.ms/pipelines/v1.0/subscriptions/df741348-6c47-45d1-9bfc-1b8dbf6a4efa/resourceGroups/aml-study-jc/providers/Microsoft.MachineLearningServices/workspaces/aml-study-jc/PipelineRuns/PipelineSubmit/b1152fb0-b19a-4909-9995-5720c5c9fc67\" target=\"_blank\" rel=\"noopener\">REST Endpoint</a></td></tr></table>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 17,
      "metadata": {
        "gather": {
          "logged": 1621008917593
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To run the pipeline from the REST endpoint, you first need an OAuth2 Bearer-type authentication header. This example uses interactive authentication for illustration purposes, but for most production scenarios requiring automated or headless authentication, use service principle authentication as [described in this notebook](https://aka.ms/pl-restep-auth).\n",
        "\n",
        "Service principle authentication involves creating an **App Registration** in **Azure Active Directory**, generating a client secret, and then granting your service principal **role access** to your machine learning workspace. You then use the [`ServicePrincipalAuthentication`](https://docs.microsoft.com/python/api/azureml-core/azureml.core.authentication.serviceprincipalauthentication?view=azure-ml-py) class to manage your auth flow. \n",
        "\n",
        "Both `InteractiveLoginAuthentication` and `ServicePrincipalAuthentication` inherit from `AbstractAuthentication`, and in both cases you use the `get_authentication_header()` function in the same way to fetch the header."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core.authentication import InteractiveLoginAuthentication\n",
        "\n",
        "interactive_auth = InteractiveLoginAuthentication()\n",
        "auth_header = interactive_auth.get_authentication_header()"
      ],
      "outputs": [],
      "execution_count": 18,
      "metadata": {
        "gather": {
          "logged": 1621008922649
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Get the REST url from the `endpoint` property of the published pipeline object. You can also find the REST url in your workspace in the portal. Build an HTTP POST request to the endpoint, specifying your authentication header. Additionally, add a JSON payload object with the experiment name and the batch size parameter. As a reminder, the `process_count_per_node` is passed through to `ParallelRunStep` because you defined it is defined as a `PipelineParameter` object in the step configuration.\n",
        "\n",
        "Make the request to trigger the run. Access the `Id` key from the response dict to get the value of the run id."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "rest_endpoint = published_pipeline.endpoint\n",
        "response = requests.post(rest_endpoint, \n",
        "                         headers=auth_header, \n",
        "                         json={\"ExperimentName\": \"Tutorial-Batch-Scoring\",\n",
        "                               \"ParameterAssignments\": {\"process_count_per_node\": 6}})"
      ],
      "outputs": [],
      "execution_count": 19,
      "metadata": {
        "gather": {
          "logged": 1621008931454
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    response.raise_for_status()\n",
        "except Exception:    \n",
        "    raise Exception(\"Received bad response from the endpoint: {}\\n\"\n",
        "                    \"Response Code: {}\\n\"\n",
        "                    \"Headers: {}\\n\"\n",
        "                    \"Content: {}\".format(rest_endpoint, response.status_code, response.headers, response.content))\n",
        "\n",
        "run_id = response.json().get('Id')\n",
        "print('Submitted pipeline run: ', run_id)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Submitted pipeline run:  ef28fd6b-80ee-4bbd-9bda-c6a2bd1ee6f0\n"
          ]
        }
      ],
      "execution_count": 20,
      "metadata": {
        "gather": {
          "logged": 1621008957079
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use the run id to monitor the status of the new run. This will take another 10-15 min to run and will look similar to the previous pipeline run, so if you don't need to see another pipeline run, you can skip watching the full output."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.pipeline.core.run import PipelineRun\n",
        "\n",
        "published_pipeline_run = PipelineRun(ws.experiments[\"Tutorial-Batch-Scoring\"], run_id)"
      ],
      "outputs": [],
      "execution_count": 21,
      "metadata": {
        "gather": {
          "logged": 1621008973905
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Show detail information of the run\n",
        "published_pipeline_run"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 22,
          "data": {
            "text/plain": "Run(Experiment: Tutorial-Batch-Scoring,\nId: ef28fd6b-80ee-4bbd-9bda-c6a2bd1ee6f0,\nType: azureml.PipelineRun,\nStatus: Running)",
            "text/html": "<table style=\"width:100%\"><tr><th>Experiment</th><th>Id</th><th>Type</th><th>Status</th><th>Details Page</th><th>Docs Page</th></tr><tr><td>Tutorial-Batch-Scoring</td><td>ef28fd6b-80ee-4bbd-9bda-c6a2bd1ee6f0</td><td>azureml.PipelineRun</td><td>Running</td><td><a href=\"https://ml.azure.com/runs/ef28fd6b-80ee-4bbd-9bda-c6a2bd1ee6f0?wsid=/subscriptions/df741348-6c47-45d1-9bfc-1b8dbf6a4efa/resourcegroups/aml-study-jc/workspaces/aml-study-jc&amp;tid=d51de596-45a0-4aa5-a0d8-47d1c958aa32\" target=\"_blank\" rel=\"noopener\">Link to Azure Machine Learning studio</a></td><td><a href=\"https://docs.microsoft.com/en-us/python/api/overview/azure/ml/intro?view=azure-ml-py\" target=\"_blank\" rel=\"noopener\">Link to Documentation</a></td></tr></table>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 22,
      "metadata": {
        "gather": {
          "logged": 1621008976142
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Clean up resources\n",
        "\n",
        "Do not complete this section if you plan on running other Azure Machine Learning service tutorials.\n",
        "\n",
        "### Stop the notebook VM\n",
        "\n",
        "If you used a cloud notebook server, stop the VM when you are not using it to reduce cost.\n",
        "\n",
        "1. In your workspace, select **Compute**.\n",
        "1. Select the **Notebook VMs** tab in the compute page.\n",
        "1. From the list, select the VM.\n",
        "1. Select **Stop**.\n",
        "1. When you're ready to use the server again, select **Start**.\n",
        "\n",
        "### Delete everything\n",
        "\n",
        "If you don't plan to use the resources you created, delete them, so you don't incur any charges.\n",
        "\n",
        "1. In the Azure portal, select **Resource groups** on the far left.\n",
        "1. From the list, select the resource group you created.\n",
        "1. Select **Delete resource group**.\n",
        "1. Enter the resource group name. Then select **Delete**.\n",
        "\n",
        "You can also keep the resource group but delete a single workspace. Display the workspace properties and select **Delete**."
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Next steps\n",
        "\n",
        "In this machine learning pipelines tutorial, you did the following tasks:\n",
        "\n",
        "> * Built a pipeline with environment dependencies to run on a remote GPU compute resource\n",
        "> * Created a scoring script to run batch predictions with a pre-trained Tensorflow model\n",
        "> * Published a pipeline and enabled it to be run from a REST endpoint\n",
        "\n",
        "See the [how-to](https://docs.microsoft.com/azure/machine-learning/service/how-to-create-your-first-pipeline?view=azure-devops) for additional detail on building pipelines with the machine learning SDK."
      ],
      "metadata": {}
    }
  ],
  "metadata": {
    "authors": [
      {
        "name": [
          "sanpil",
          "trmccorm",
          "pansav"
        ]
      }
    ],
    "kernelspec": {
      "name": "python3-azureml",
      "language": "python",
      "display_name": "Python 3.6 - AzureML"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.9",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "msauthor": "trbye",
    "categories": [
      "tutorials"
    ],
    "kernel_info": {
      "name": "python3-azureml"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}